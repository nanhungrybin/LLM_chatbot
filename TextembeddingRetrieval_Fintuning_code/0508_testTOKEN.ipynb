{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizerFast, BertForMaskedLM, BertConfig, AdamW\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "from datetime import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/llm-rag-embeddings/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1717373475693
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 데이터"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 경로 설정 : 데이터를 읽어오는 곳\n",
        "    \n",
        "# path = \"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/CODE/사출성형/tokenizer_data/\"\n",
        "\n",
        "# all_texts = []\n",
        "\n",
        "# # 폴더 내의 모든 txt 파일의 데이터를 모음\n",
        "# for file in os.listdir(path):\n",
        "#     if file.endswith('.txt'):\n",
        "#         file_path = os.path.join(path, file)\n",
        "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
        "#             all_texts.append(f.read())\n",
        "\n",
        "# file_paths = [os.path.join(path, file) for file in os.listdir(path) if file.endswith('.txt')] #list\n",
        "\n",
        "\n",
        "# # 데이터셋 로드\n",
        "# dataset = load_dataset('text', data_files=file_paths, cache_dir='/home/azureuser/cloudfiles/code/Users/hb.suh/cache')\n",
        "\n",
        "# from datasets import DatasetDict, Dataset\n",
        "\n",
        "# # 훈련 데이터셋을 훈련 세트와 검증 세트로 분할\n",
        "# train_test_split = dataset['train'].train_test_split(test_size=0.2)\n",
        "\n",
        "# # 분할된 데이터셋을 다시 DatasetDict로 구성\n",
        "# dataset = DatasetDict({\n",
        "#     'train': train_test_split['train'],\n",
        "#     'valid': train_test_split['test']\n",
        "# })\n",
        "\n",
        "# print(dataset)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717082435574
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "새로 수집한 데이터"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "\n",
        "# 여러 경로를 리스트에 저장\n",
        "text_paths = [\n",
        "    \n",
        "    \"/home/azureuser/cloudfiles/code/Users/hb.suh/(0522part)_번역원본\",\n",
        "    \"/home/azureuser/cloudfiles/code/Users/hb.suh/(0527part)_번역원본\",\n",
        "    \"/home/azureuser/cloudfiles/code/Users/hb.suh/(0522part)_OnlyTranslatedData/사출성형\",\n",
        "    \"/home/azureuser/cloudfiles/code/Users/hb.suh/(0527part)_OnlyTranslatedData\"\n",
        "]\n",
        "\n",
        "before_paths = [\"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/CODE/사출성형/tokenizer_data/\"]\n",
        "\n",
        "json_paths = [\n",
        "    \"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/CODE/TestGPT_data/\"\n",
        "]\n",
        "\n",
        "\n",
        "main_content_texts = []\n",
        "for onepath in text_paths:\n",
        "    for file in os.listdir(onepath):\n",
        "        if file.endswith('.txt'):\n",
        "            with open(os.path.join(onepath, file), 'r', encoding='utf-8') as f:\n",
        "                lines = f.readlines()\n",
        "                main_content = \"\"\n",
        "                extract = False\n",
        "\n",
        "                for line in lines:\n",
        "                    # \"main_content:\" 또는 \"Main Content:\"로 시작\n",
        "                    if line.strip().lower().startswith(\"main_content:\") or line.strip().lower().startswith(\"main content:\"):\n",
        "                        if extract and main_content:\n",
        "                            # 이전에 추출된 main_content를 추가합니다.\n",
        "                            main_content_texts.append(main_content.strip())\n",
        "                            main_content = \"\"\n",
        "                        extract = True\n",
        "                        # \"main_content:\" 이후의 내용을 추출합니다.\n",
        "                        main_content = line.strip().split(\":\", 1)[1].strip()\n",
        "                    elif extract:\n",
        "                        if line.strip() == \"\":\n",
        "                            # 빈 줄이 나오면 추출을 중지하고 main_content를 추가합니다.\n",
        "                            main_content_texts.append(main_content.strip())\n",
        "                            extract = False\n",
        "                            main_content = \"\"\n",
        "                        else:\n",
        "                            # 이어지는 줄을 main_content에 추가합니다.\n",
        "                            main_content += \" \" + line.strip()\n",
        "\n",
        "                # 파일 끝에 도달했을 때 남아있는 main_content를 추가합니다.\n",
        "                if main_content:\n",
        "                    main_content_texts.append(main_content.strip())\n",
        "\n",
        "main_content_texts[2]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "'ABSTRACT Printed electrolyte-gated transistors (EGTs) are an emerging biosensor platform that leverage the facile fabrication engendered by printed electronics with the low voltage operation enabled by ion gel dielectrics. The resulting label-free, nonoptical sensors have high gain and provide sensing operations that can be challenging for conventional chemical field effect transistor architectures. After providing an overview of EGT device fabrication and operation, we highlight opportunities for microfluidic enhancement of EGT sensor performance via multiplexing, sample preconcentration, and improved transport to the sensor surface. Published under license by AIP Publishing. https://doi.org/10.1063/1.5131365 1. INTRODUCTION Surface-based adsorption, where an analyte of interest is pulled down from a solution by a specific capture agent, such as an antibody, is a standard biosensing method. These surface adsorption-based assays typically rely on an optical readout, such as the fluorescence-based measurements used in DNA microarrays 1 or the changes in refractive index obtained by surface plasmon res- onance (SPR). 2 Electronic-based detection provides a potentially simpler readout of the binding event, obviating the need for the labeling steps in a fluorescence-based readout or the optical align- ment required for sensitive methods such as SPR. Transistor-based methods, including field effect transistors (FETs) and electrolyte gated transistors (EGTs), provide one possible route toward elec- tronic detection, where the binding event changes the threshold voltage required to turn the transistor ON. This perspectives article focuses on recent advances in bio- sensing using electrolyte gated transistors and opportunities for improving the technology via microfluidics. In an EGT, the gate dielectric typical of a conventional FET is replaced with a liquid or gel electrolyte. There are two basic modes of EGT operation: elec- trochemical and electric double layer. In the electrochemical mode, application of a gate voltage drives electrochemical oxidation or reduction of the semiconductor channel with accompanying pene- tration of ions into the semiconductor. In the electric double layer mode, ions do not penetrate the semiconductor. Instead, the gate voltage drives the formation of a sheet of carriers (electrons or holes) in the semiconductor and an oppositely charged sheet of ions in the electrolyte immediately adjacent to the semiconductor. Both modes enhance the conductivity of the semiconductor channel by increasing the free carrier density. In most of our bio- sensing work, we have exploited EGTs based on the benchmark polymer semiconductor poly(3-hexylthiophene), or P3HT, which is permeable to ions. Thus, the P3HT EGTs operate in the electro- chemical mode. Irrespective of the mode of operation, all EGTs have the property that they work at very low voltages because of the enormous capacitance of electrolytes; low voltage operation, in turn, makes the devices sensitive to label-free chemical binding to surfaces, as described below. The EGT is an emerging platform, and much of the research 3-32 to date has focused on proof-of-principle detection or funda- 17,28,33-41 mental studies of the device operation. However, the EGT platform and, in particular, the length scales accessible by printed electronics, make printed EGTs ideally suited for microfluidic integration. Microfluidics thus has the potential to dramatically improve EGT sensors via facile multiplexing, sample preconcen- tration, and improved transport to the surface. This perspectives article is not intended to provide a compre- hensive review of FET and EGT biosensors, and readers interested 42-45 in a more thorough recent overview are referred elsewhere. Rather, this perspective aims to provide sufficient background on the sensing technology for the microfluidics community to identify and take advantage of opportunities in EGT sensing, with a particular emphasis on the floating-gate EGT platform developed in our labs. II. CHEMICAL FIELD EFFECT TRANSISTORS The principle of detecting a chemical in solution via transduc- tion by a FET, known as a ChemFET, was introduced in the 1970s, and Janata. 49,50 with the earliest work pioneered by Bergveld 46-48 Figure 1 illustrates the basic principle behind different variants of a ChemFET. In the absence of any applied gate voltage, the FET is in the OFF state. As the gate voltage increases, the increasing electric field created within the semiconductor channel causes the transistor to turn ON at the threshold voltage, VT, producing a sharp increase in current between the source and the drain electrodes. The differ- ence in current between the ON and OFF states is typically orders of magnitude. In the saturation regime, the drain current is given by51 where the width and length of the semiconductor channel are W and L, respectively, m is the carrier mobility within the semiconduc- tor, and Ci is the specific capacitance of the gate dielectric. The latter quantity plays a key role in EGT-based sensing; we will return to the importance of Ci in Sec. III A. In a ChemFET, the solution containing the analyte is placed between the gate electrode [Fig. 1(b)] and the dielectric surface. Adsorption of the analyte to the dielectric produces a shift in the threshold voltage due to a change in the interfacial potential of the dielectric/solution surface. Measuring the difference in threshold voltage, △VT, between the ChemFET in the presence and absence of the analyte thus provides a way to quantify chemisorption onto the FET surface. The particular example in Fig. 1(b) corresponds to the binding of an antibody to the dielectric surface, but one can use other capture agents, such as aptamers, or change the binding site to the semiconductor itself. 54-59 In general, the ChemFET architecture in Fig. 1(b) poses signif- icant materials science challenges for biological detection because (i) the capture agent must be bound directly to the thin dielectric and (ii) the dielectric is in contact with the aqueous medium. In particular, it is generally the case that the molecular grafting chem- istry available for dielectric materials such as SiO2 is not as well- controlled or as convenient as the grafting chemistries applicable to noble metals such as silver, gold, or platinum. This limits the ability to attach capture molecules in an oriented fashion to the dielectric. Additionally, in order for the ChemFET to sense small threshold voltage shifts associated with chemical binding, the dielectric layer needs to be extremely thin (a few tens of nanome- ters), and this makes the whole device susceptible to leakage cur- rents associated with ion migration in and out of pinholes in the thin dielectric. These considerations significantly limit the applica- tion of ChemFETs with the Fig. 1(b) architecture in applications where the analyte solution is a biofluid, such as blood, or situations where the reagents needed to extract the analyte from a complex medium also serve as etchants for the dielectric. One approach to the material incompatibility problem is to use an ion-selective membrane between the FET and the aqueous medium [Fig. 1(c)], which is the basis of an ion-selective field effect transistor (ISFET). 47 After initial demonstration by Bergveld, 47,60 ISFETs have been used in a variety of applications, 52 61 such as recent applications for pH sensing in coastal waters, 62,63 blood glucose sensing, monitoring the metabolic activity of cell populations, 64-66 and the detection of disease biomarkers in blood67 and sweat. The Ion Torrent DNA sequencer is arguably 68 the most successful application of the ISFET principle for biological applications. This sequencer uses a tantalum oxide layer to provide proton sensitivity, along with a fluidic well above the oxide layer. The DNA templates are ligated to beads, and each well contains a single bead. This device uses a sequencing-by-synthesis protocol, where the ISFET detects the local change in pH due to the release of a proton when a base is added. The Ion Torrent sequencing approach leverages the ability to create a very dense array of identical sensors using CMOS manufacturing methods, with 13 x 106 sensors on a single chip for massively parallel, nonoptical DNA sequencing. A second approach to solve the material incompatibility problem is the extended gate 53 illustrated in Fig. 1(d). concept Here, the gate electrode is extended away from the semiconductor, which allows one to create a separate aqueous environment. The extended gate architecture is also called a floating gate3 to highlight that the potential of the gate electrode in contact with the transistor is no longer directly imposed by the gate voltage. Rather, the gate voltage is applied at another electrode within the aqueous medium and capacitively coupled to the floating gate, which is then con- nected to the FET. Traditional FETs with extended gates have been 53 utilized extensively for applications such as chemical sensing, pH 70-72 73,74 75-77 proteins, and sensing, and the detection of DNA, small molecules. 78,79 Both the ISFET and the extended gate ChemFET provide routes toward biosensing in challenging environments, but these methods also have their limitations. Clearly, while the ISFET archi- tecture protects the transistor from the medium through the ion selective membrane, not all biosensing applications can be accom- plished with an ISFET configuration. The most notable example is antibody/antigen binding, which underlies highly specific and highly sensitive immunogenic biosensing methods. The extended gate architecture is more flexible and can accommodate any capture agent that can be bound to the extended gate, which is often gold. Antibodies are often used as the capture agents in these 75,76 but aptamers 77,79 devices, have also been used for the detection of proteins and DNA with extended gate FETs. However, the extended gate FET is not optimal from a fabrica- tion perspective. Explicitly, the cost of CMOS fabrication is propor- tional to the area. This scaling is the reason, in part, why the Ion Torrent DNA sequencer 69 exemplary use of FETs for chemi- is an cal sensing; it is relatively easy to create a dense array of millions of identical sensors, and DNA sequencing benefits from such mas- sively parallel operation. However, if one is making a dedicated bio- 70-77,79 this advantage is lost. Rather, one sensor for a single target, needs to forgo substantial chip real estate to add the extended gate into an integrated device. Alternatively, one can connect a commer- 70-73,80,81 cially available FET part to an extended gate electrode, 74-77,79 design and fabricate a custom MOSFET for the sensor, or directly functionalize the leads of the FET device. 82 The resulting devices are inexpensive but can lead to incommensurate sizing of the floating gate with respect to the FET channel. Essentially, one wants the capacitance of the sensing surface at the end of the extended gate electrode [C2 in Eqs. (2) and (3) appearing below] to be comparable to the capacitance of the gate/insulator/semiconduc- tor stack in the FET. Such a situation ensures sensitivity to chemi- cal binding events on the extended gate electrode. However, commercial FETs are tiny, and so one generally has a mismatch between the size of the extended gate, its sensing area, and the size of the commercial FET. This is not an insurmountable problem, but it is a consideration when one is considering high throughput, low cost manufacturing of relatively large, individual sensors. III. PRINTED ELECTROLYTE-GATED TRANSISTORS We have been pursuing an alternate strategy, based on printed electrolyte-gated transistors (EGTs), that is well suited for microfluidic sensing using a floating (extended) gate architecture. As the name implies, this device merges two concepts: printed electronics and electrolyte gating. We briefly describe each of these concepts below. A. Electrolyte gating As its name implies, an EGT uses an electrolyte to gate the transistor, rather than a conventional dielectric. It is worthwhile to clearly define an EGT here, as there is some inconsistency in the lit- erature (including in our own publications). The ISFET and extended gate FET in Fig. 1 can be considered \"electrolyte-gated FETs;\" the field effect transistor is still gated by a conventional dielectric, but there is a salt solution that is in series with the dielectric between the gate electrode and the semiconductor. We define an EGT (Fig. 2) to correspond to systems that do not have the dielectric layer such that the electrolyte is in direct contact with the semiconductor. The tran- sistor is gated by either having ions from the electrolyte penetrate into the semiconductor or through the creation of an electric double- layer proximate to the semiconductor. Owing to the permeability of organic semiconductors, it is also possible to have mixtures of both 51 current mechanisms within a single transistor. Our EGT sensors rely on the first approach by replacing the dielectric layer with an ion gel. 8 3 An ion gel comprises an ionic liquid that is mechanically stabilized by a block polymer; our sensing experiments3-5333.34 use 1-Ethyl-3-methylimidazolium bis (trifluoromethylsulfonyl)imide (EMIM/TFSI) as the ionic liquid and poly(styrene)-b-poly(ethyl acrylate)-b-poly(styrene) as the stabil- 84 This system forms a gel because the poly(styrene) blocks of izer. the copolymer are less miscible with the ionic liquid than the poly (ethyl acrylate) blocks, creating a network of nodes of poly(styrene) that are bridged by the poly(ethyl acrylate) chains within a matrix of ionic liquid. When an electric field is applied to the ion gel, the ions penetrate the semiconductor [Fig. 2(c)] to create a dense collec- tion of holes. The 30 nm thickness of the semiconductor layer leads to very high specific capacitances of Ci 2 100 �F/cm2. 51 Our EGTs have a lot of similarity to so-called organic electro- chemical transistors (OECTs), which employ aqueous electrolytes instead of the ion gel and often use the conducting polymer PEDOT:PSS as the channel material. 43,85 The mode of operation of PEDOT -based OECTs is electrochemical like our P3HT EGTs, the difference being that the PEDOT OECT is normally ON when the gate voltage is off. A positive gate voltage turns the device OFF. OECTs have been used in a variety of chemical sensing schemes which have recently been reviewed. 43,44 In general, EGTs (and OECTs) have a high specific capaci- tance, owing to the charge separation illustrated in Figs. 2(b) and 2(c), and consequently operate at a lower voltage when com- pared to polarizing a conventional dielectric layer. In the context of Eq. (1) for the transistor drain current in the saturation regime, the resulting large value of Ci implies that small changes in the thresh- old voltage VT created in a sensing environment are amplified into large changes in the drain current. This amplification is the origin of the high quasistatic gain achievable with EGTs. One of the limitations of ion gels in EGTs is that the switching time (105-106 Hz) in the best cases 86 considerably slower than is conventional FETs. Slow switching is a limitation in computing applications. For example, typical modern central processing units (CPUs) have switching speeds in the GHz range, far faster than it is possible to polarize and depolarize an ion gel. Fortunately, such switching speeds are overkill for a biosensor. Rather, the rate-limiting step for biosensing is the mass transport to the sensor surface, which typically occurs on time scales of minutes. As a result, sweeping the gate voltage at circa 50 mV/s, which leads to good sensing perfor- mance, corresponds to sampling rates of circa 20 s. Such rates are sufficient to establish equilibrium binding to the surface. B. Printed electronics Additive manufacturing methods such as printing are particu- larly attractive for low cost production of high-volume, single-use sensors, especially because they can be implemented in continuous roll-to-roll formats common to the newsprint, publishing, and packaging industries. 87-90 Widespread, commercially successful examples of printed sensors include glucose test strips and the 91,92 Indeed, the increased availability of elec- home pregnancy test. tronic inks based on conducting, semiconducting, and insulating materials makes printing of complete EGT-based sensors achiev- able. There are already examples in the literature of sheet-based aerosol-jet and ink jet printed FET- and EGT-based circuits that have more complexity than the sensor designs discussed 51,93-95 here. However, a challenge is to translate these early results to roll-to-roll processes and such research is ongoing. Currently, our printed EGT devices use a combination of con- ventional lithography and printed electronics illustrated in Fig. 3. In the first step, we lithographically pattern gold-on-chrome elec- trodes onto a silicon wafer in the desired locations. We then print the semiconductor, which in our case is the organic semiconductor poly(3-hexylthiophene), or P3HT. P3HT is dissolved in chloroform with terpineol added as a cosolvent. P3HT is then printed over the source and drain electrode using an aerosol-jet printer. The ion gel is printed subsequently over the channel and the gate electrode, thereby completing the EGT circuit. Following this, polstyrene is printed over the ion gel as an encapsulation layer. This prevents oxygen from diffusing through the ion gel and doping the semicon- ductor on the time scale of our experiments. In contrast to CMOS electronics, the length scales accessible by printed electronics are ideally suited for integration with micro- fluidics. The component size for printed electronics is set by the size of the spots of ink that can be deposited during printing; for aerosol-jet printing, this sets the feature sizes to be circa 10 um. Soft lithography in PDMS using SU-8 molds readily produces flu- It is relatively easy to increase the idics with these length scales. 96 feature size in printed electronics, which opens the possibility for 97-100 creating molds from simpler methods (e.g., 3D printing rather than lithographically producing SU-8 molds. We have produced our devices on a silicon substrate, which easily bonds to the PDMS microfluidics. It is also possible to print devices on a wide range of substrates, including glass and flexible 101-106 substrates. While glass is easily used with PDMS microflui- dics, the polymeric substrates can pose integration challenges with the PDMS. A possible solution to the integration problem is to print both the electronics and the microfluidics, as done for a 107 recently reported sensor. IV. OPERATION AND APPLICATIONS OF EGTS FOR BIOSENSING A. Mechanism of detection in a floating gate EGT Figure 4(a) provides a schematic representation of an EGT biosensor using a floating gate architecture. The left side of the device is the EGT analogous to Fig. 2(a). The left arm (FG1) of the floating gate electrode communicates with the aqueous environ- ment electronically by a via to the right arm (FG2) of the floating gate. The right arm of the floating gate is functionalized with the capture agent and communicates through the aqueous electrolyte to the control gate. This architecture is quite flexible with respect to the right arm of the floating gate, and we have demonstrated protein binding to sensing functionality for DNA hybridization, 3 DNA aptamers, 4,5 binding to antibodies, 5 and self- protein assembled monolayers (SAMs)33,34 on the floating gate. In an experiment using the setup in Fig. 4(a), we sweep the control gate voltage, VG, and measure the drain current, ID, between the source and drain electrodes, producing a transfer curve such as the one in Fig. 4(b).3 4% As the gate voltage becomes more negative, the transistor turns ON and the drain current increases, which is the expected behavior for a p-type semiconductor such as P3HT. From Eq. (1) for a transistor in the saturation regime, the threshold voltage VT is obtained from a plot of I1/2 VS VG by extrapolating the linear fit to zero current. We have conducted a series of systematic experiments 33,34 to determine how the voltage VG imposed on the control gate is related to the voltage VF at the floating gate, since VF is responsible for polarizing the ion gel and thus turning ON the EGT. The first Printing of an EGT. The P3HT and ion gel are aerosol- sequentially onto a silicon aerosol-jet printing, illus- schematically in the upper panel, carrier flow containing the rele- (P3HT or ion gel) and a that focuses the carrier jet surface. The electrodes and pads are created prior to print- using the conventional set of experiments33 varied the size of the electrodes to investigate the role of the relative capacitances of each interface. These experi- ments revealed that the device operation is captured by the equiva- lent circuit model in Fig. 4(c). Applying voltage to the control gate sets up double layers at all of the interfaces within the device except the semiconductor/ion gel interface, where electrochemical doping occurs [e.g., Fig. 2(b)]. The double layers and electrochemical doping can be modeled by their capacitance. These interfaces can then be lumped into two overall capacitances, with C1 representing the capacitance of interfaces on the ion gel side of the device in Fig. 4(a) and C2 representing capacitances within the aqueous phase. A model with only these two capacitors predicts that Unfortunately, this model fails to capture the experimental data as 33 the ratio of the floating gate area to the P3HT area changes. Rather, we need to include an additional parasitic capacitance that accounts for a charge, Q* that can be stored elsewhere within the device. The exact nature of this parasitic capacitance remains a subject of investigation, but we have speculated33 that a fraction f of the charge that would otherwise be stored on the floating gate is lost to the parasitic capacitor. As a result, that charge is no longer available to bias the transistor, shifting the ID - VG response. The analysis of the complete circuit model in Fig. 4(c) furnishes33 where f is the fraction of the charge on C2 that is stored in the par- with asitic capacitor. Equation (3) fits the experimental data 33 f = 0.77, and a more detailed discussion of this effect appears in Ref. 33. Equation (3) reveals that the sensor is capable of detecting the accumulation of the material near the floating gate surface FG2 since this material would affect C2 and thus the relationship between the applied control gate voltage and the floating gate voltage that is turning the transistor ON. This effect is easily veri- fied by creating self-assembled monolayers (SAMs) of alkane thiols of varying lengths at the gold FG2 surface 33 since the capacitance 108 of the SAM is an inverse to the thickness of the layer. In the context of biosensing, such changes could occur due to the capture of large neutral molecules. 17 Palazzo et al., using an EGT with the gate electrode above the electrolyte [i.e., the EGT equivalent to the ChemFET configura- tion in Fig. 1(b)], proposed that there exists an additional capaci- tance within the device that was not considered directly in our previous work. 33 Explicitly, the lumped capacitance C2 in our model arises from the pair of capacitors due to the double layers formed at the control gate and the floating gate. Palazzo et al. 17 proposed that, for biosensing, there exists a capacitor between the two in our model that accounts for the formation of a Donnan equilibrium created by the immobilized charges at the capture site. From an operational standpoint, the additional capacitance created by the Donnan layer does not affect Eq. (3) because it would appear within the lumped capacitance C2. However, the presence of a Donnan layer permits capacitive sensing outside the Debye layer, thereby overcoming a key limitation of field effect transistor detection. It is also worthwhile to understand how the sensor responds to the accumulation of charge, for example, during DNA hybridization or the capture of charged macromolecules. To decouple charge accumulation from changes in capacitance, 21 May 2024 23:47:53 subsequent experiments34 took advantage of a SAM of 11-mercaptoundecanoic acid (MUA) adsorbed onto the right arm of the floating gate. MUA is deprotonated by increasing pH, which leads to the accumulation of a charge close to the surface, without a change in capacitance. 109 These experiments revealed that the model in Eq. (3) in the presence of charge 34 accumulation becomes where DF accounts for potential changes on the right arm of the floating gate. While we have focused here on how D⌀ arises due to charge accumulation at the sensor surface by deprotonation of a SAM, 34 such potential changes could arise from the adsorption of a charged molecule such as DNA or from adsorption-induced surface dipoles. 33,34 Equation (4) illustrates the advantage of working at low voltages, since we want the device to be sensitive to the D⌀ term, which is typi- cally a few hundred mV for SAMs and DNA. Equation (4) represents our current working model for EGT detection, where the potential VF on the floating gate plays the role 있어요. of the gate voltage in Eq. (1). Following (1), changes in capaci- tance lead to a change in the slope of VS VG, while changes in surface potential lead to a horizontal shift in the curve. We can thus discern the sensing mechanism directly from the inspection of the transfer curves obtained with and without a given analyte. B. Device layout for biosensing The device layout used in Fig. 4 is ideal for understanding the basis for EGT biosensing but is less useful for applications. First, the use of a quiescent fluid above the sensing pad leads to slow dif- fusional transport to the sensor surface. Second, comparing the threshold voltages for two different scenarios is suboptimal in terms of the signal gain. Figure 5 provides a more robust biosensor layout for EGT detection. 4 To improve detection time, the system uses flow over the sensing area of the floating gate. Since the floating gate needs to be capacitively coupled to the control gate, there is an additional flow from the control gate toward the floating gate, which keeps the control gate pristine. To improve detection sensitivity, the sensor is configured as an inverter by adding a resistor between the drain and the supply voltage. The output voltage, Vout, is obtained between the drain and the load resistor. Figure 5(b) shows the advantage of operating the device as an inverter. As the input voltage to the control gate is swept to negative voltages, there is a rapid rise in the output signal over a very small change in Vin, i.e., a high gain. Subtracting two inverter curves gives a distinct peak in the output voltage, which we interpret as the signal for sensing applications. Measuring ID - VG curves or Vout from an inverter 111 but the inverter configuration provides equivalent information, is preferable due to the gain. We also find converting the inverter output to signal peaks, as in Fig. 5(b), to be an intuitive way to visualize the data when compared to analyzing differences between ID - VG curves. C. Biosensing applications Our first work using the EGT platform3 focused on the detec- tion of DNA hybridization using the quiescent fluid device in Fig. 4(a). These experiments demonstrated the proof-of-principle for the platform; the hybridization equilibrium was well described by a Langmuir isotherm, with sensitivity to mismatches in the target strand. However, the sensitivity of the device was relatively low, especially when compared with fluorescence detection. Our subsequent biosensing work4,5 thus took advantage of the flow-based inverter configuration in Fig. 5(a) for faster, more sensi- tive analysis. The first experiments demonstrated the ability to 110 detect ricin subunit B using a DNA aptamer as the capture agent. Figure 6 shows that the EGT platform can successfully detect ricin at low concentrations, even from relatively complex food matrices such as milk and orange juice, without any sample cleanup or preconcentration. The approach to measure the inverter signal for these experiments is illustrated in Fig. 5(b), using the peak of Vout as the signal. There is a slight reduction in the sensitiv- ity of the device in complex media, which is consistent with previ- ous experiments using this DNA aptamer110 and thus attributable to the binding agent rather than the sensor architecture. We have also demonstrated the detection of gluten in the EGT platform. 5 This is a considerably more challenging sensing problem, due to the strongly reducing chemicals needed to extract gluten from food 112 and the ill-defined chemical nature of gluten, which varies by source. In addition to detection using a DNA 113 also used a commercially available antibody for aptamer, we wheat gluten 114 antibody for barley gluten. 5 and raised a custom These different capture agents were challenged with different con- centrations of gluten extracted from barley, wheat, and corn, where the latter serves as the control experiment. In addition to achieving detection down to the \"gluten-free\" limit of 1 ug/ml of gluten and negligible signal for the corn control, the three different sensors each yielded different responses depending on whether they were challenged with wheat or barley. This result opens up the potential for using an array of EGTs and capture agents to obtain chemical fingerprints for complicated analytes. 5 Overall, we have demonstrated that EGTs can achieve com- petitive sensitivities in a label-free, nonoptical format from complex matrices without the need for any sample cleanup or preconcentration. 4,5 The selectivity of the sensor arises from the dissociation constant, KD, for the capture agent, and we have gen- erally been able to achieve a limit-of-detection of approximately 0.1KD, where KD has units of concentration. Since the sensing pad is a gold electrode, there are no impediments to using either DNA aptamers 4,5 or antibodies as the capture agent. Moreover, it is rel- atively easy to passivate the surface with poly(ethylene glycol) to prevent nonspecific adsorption. 4 There exist approaches to bind capture agents to and passivate other surfaces, but gold is particu- larly convenient to use because the chemistry for these reactions is very mature. EGTs without an extended gate have also demonstrated com- petitive sensivities. Recent studies from the Torsi group have evi- denced EGTs that can achieve a limit of detection down to a single protein via functionalization of the gate electrodes with chem-SAMs and bio-SAMs, using bovine serum albumin (BSA) to passivate the surface. 28,31 of the Debye Due to the limitations length, de-ionized water was used as the gating electrolyte. The model proposed for the sensing mechanism of the single-molecule transistor (SiMoTs) assumes domains of SAMs that electrostatically cooperate through hydrogen bonding. Once the protein is bound to the bio-SAM, there is a change in the work function of the gate electrode that is propagated through the domain, which, in turn, changes the threshold voltage of the SiMoT, as shown in Fig. 7. Other gate-functionalized EGTs have also exploited SAM chemistry 13 to selectively react with biomolecules, such as dopamine, while others have used different methods to immobilize antibodies 37,38 aptamers, 24 cells, 2 7 and proteins. 20 Similar to ChemFETs, the semiconductor of EGTs can be functionalized with capture agents at the semiconductor surface, and the chemistry can be tailored to expose a variety of biorecep- 21,32 eliciting a change in capacitance upon tors. In addition to binding, the semiconductor channel can also become doped. The response is thus a change in the drain current, or shift in the threshold voltage, depending on the type of doping. Hao et al. demonstrated this through functionalization of graphene with aptamers that specifically bind to insulin, causing deformation of the aptamer, as shown in Fig. 8.21 The pH of the electrolyte (7.4) was above the isoelectric point of insulin (5.8), so the insulin was weakly and negatively charged, causing the change in current and the Dirac voltage to be attributed to charge transfer from either the insulin or the deformed aptamer. In the case of organic electro- chemical transistors, electrochemical doping of the ion permeable channel is responsible for the functionality of the sensor. Organic electrochemical transistors also elicit a change in the effective gating, or electrochemical doping, upon binding events at the func- 11 tionalized channel surface and have been used to sense bacteria, 23 25 metabolites, and viruses. FIG. 7. SiMoT sensing measurements. (a) Transfer curves with varied IgG concentrations of 6 zeptoMolar (zM, black curve), (6 土 3) x 10 zM (blue curve), (6 土 1) x 102 zM (dark curve), (6.7 土 0.1) x 103 zM (magenta curve), and (6.67 土 0.01) x 106 zM (light green curve) in PBS standard solutions. (b) Negative shifts in the work function with corresponding threshold voltage shifts at each functionalization step. EF is the gate electrochemical potential and VL is the vacuum level. Reproduced with permission from Macchia et al., Nat. Commun. 9, 3223 (2018). Copyright 2018, Author(s), licensed under Attribution 4.0 International (CC BY 4.0). The compatibility between the electrolyte and the semicon- ductor limits the versatility of this approach but can be overcome by the usage of an ion selective membrane 16 or by passivating the 14,17 surface with the bioreceptor. Functionalization of a phospho- lipid bilayer containing the capturing agents to the organic semi- conductor surface causes capacitance changes at the semiconductor/electrolyte interface. The use of the phospholipid layer prevents ion diffusion from the electrolyte into the semicon- ductor, confirmed by low hysteresis in ID-VG curves along with low (nA) gate leakage currents. The sensing mechanism for the reported capture of negatively charged proteins, such as streptavi- din and C-reactive protein, is the increase in drain current and shift in threshold voltage compared to EGTs with no exposure to the protein. 28 both specific detection of This approach allows for biomolecules and detection beyond the Debye length in high ionic strength solutions (lD = 0.7 nm) through the formation of Donnan equilibrium at the protein capture site. V. OPPORTUNITIES FOR MICROFLUIDICS IN EGT BIOSENSORS Having provided an overview of EGT biosensing, we now explore a trio of possible approaches to improve EGT detection in the future via microfluidics. We consider both straightforward modifications, as well as some more speculative ideas related to control of the environment near the sensor surface. A. Sensor multiplexing Multiplexing of the sensors represents the most straightfor- ward approach to improve sensor performance. There has been only minimal work toward multiplexing of EGT sensors, despite the relative simplicity of the process. For example, we have con- nected two sensors in the same inverter circuit* to provide direct subtraction of the reference and test sensor during a measurement. We also fabricated multiple instances of the flow-based device in Fig. 5 on a single wafer for our multipixel approach to gluten detec- tion. 5 While useful steps forward, neither of these approaches takes advantage of the inherent advantages of microfluidics to create rela- tively complicated fluidic flow paths, especially in compact formats, that would enable improved device performance. For a given target, it is desirable to make four measurements per sample, using all combinations of blank solution VS sample sol- ution and functionalized sensor VS blank sensor. Such an experi- ment could be implemented using a multiplexed design. This quartet of experiments provides a complete set of control experi- ments. As indicated by the error bars in Fig. 6, there is also some variability in the signal obtained from a single EGT sensor. While the latter variability is sure to decrease as the EGT biosensor plat- forms mature, in particular, if they ultimately move to a commer- cial fabrication facility, it likely will remain desirable to add an additional layer of multiplexing to capture sensor-to-sensor vari- ability as well. Even a 5-fold test would only involve 20 separate sensors on the chip, well below the massive levels of integration that have been achieved in microfluidic devices for almost 20 years 115 now. Internal calibration can be achieved by subtracting the output of two EGTs to measure relative amounts. A key challenge in creating multiplexed devices is separately functionalizing different sensors on the device and alignment of the fluidics with the printed sensors. The former problem is readily solved by reversibly bonding a fluidic layer for flowing solution over the desired sample pads and then replacing that layer by the fluidic system for sample handling prior to use. Alternatively, if the pads are large enough, simply creating wells above each pad for functionalization is possible. The alignment of the microfluidics does not represent a significant challenge due to relatively large sizes of the control gate and floating gate required to optimize the device operation. We thus view multiplexing as the most natural microfluidic route for immediate improvements in EGT biosensors. B. Sample preconcentration Our experiments 4,5 revealed that our EGT sensor typically operates with a limit of detection of 0.1KD for the capture agent. The limit of detection in the EGT is affected by the device-to-device variability in the signal, as indicated by the error bars in Fig. 6 and the noise in the control experiment. Both of these device-related issues can be ameliorated somewhat by improvements in both the fabrication process and the device design. But, it is also desirable to consider approaches to improve the limit of detection via microfluidics. The standard approach to lower the limit of detection is sample preconcentration prior to analysis, such that the sample sent to the sensor is at a higher concentration than the original material. Sample preconcentration effectively acts as a multiplica- tive factor for the limit of detection. One particularly attractive method for sample preconcentra- tion within a microfluidic device for charged molecules is isotacho- 116 thorough phoresis (ITP). Eid and Santiago have provided a recent review of ITP, with a particular focus on how ITP can improve heterogeneous biomolecular reactions such as those arising from capture agents bound to the surface of a sensor. Briefly, ITP involves two electrolytes, a leading electrolyte with a high electrophoretic mobility and a trailing electrolyte with a low electrophoretic mobility. If the analyte of interest has an electro- phoretic mobility that lies between the trailing and leading electro- lytes, it will become concentrated at the interface between them. The thickness of the interface between the different electrolytes is set by molecular diffusion and is thus quite sharp. A particularly attractive feature of ITP is that it is a self-focusing method, since analytes in the leading electrolyte will fall behind (and vice versa for the trailing electrolyte), so there is no need to provide a sharp injection plug of the sample. Indeed, one of the limitations in ITP is that the sample plug may pass over the sensor so quickly that the time for reaction at the surface becomes a limiting factor. This 117 effect can be attenuated by using a stop-and-diffuse approach, where the electric field is turned off when the sample plug reaches the sensor, thereby allowing additional time for reactions from the concentrated sample. Although million-fold increases in sample concentration are theoretically possible, typical enhancements in biological fluids are around 10 000-fold. 116 Compared to a fluorescence-based assay, there are some minor challenges to implementing ITP in an EGT. It is unlikely one can simultaneously apply an electric field to drive the ITP while also modulating the gate voltage, as the ITP electric field would affect the potential at the gate electrode. Figure 9 illustrates a possible approach based on a pulsed ITP method. At the start of the process, ITP is used to focus the sample. Since we are using a label-free method, this band cannot be imaged in the manner used for fluorescence-based detection. If the sample has not reached the detector, then there should be no signal. The ITP can be turned on and off repeatedly while driving the analyte toward the sensor surface. We expect to see a sudden spike in the △V signal when the ITP band reaches the sensor surface. At this point, the pulsed ITP operation can be stopped and we can use a conventional EGT mea- surement by sweeping the gate voltage. Note that, since ITP is a focusing method, there is no loss in sensitivity by periodically releasing that electric potential and allowing the ions to diffuse; once the potential is reapplied, the bands will automatically sharpen again. As an effect, the proposed operating method is akin until the to running many \"stop-and-diffuse\" ITP protocols 117 analyte band reaches the sensor surface. The key challenge is bal- ancing the rate of switching between ITP and EGT sensing and the magnitude of the electric potential driving the electrophoresis of the analyte band to the sensor surface. The second challenge is identifying an appropriate leading and trailing electrolyte for new analytes of interest, although ITP recipes have been developed for a large number of useful biological moieties, in particular, for nucleic acids in complex media. 118 C. Improved transport to the sensor surface In addition to increasing the equilibrium binding to the surface, preconcentration also increases the kinetics of the reaction through an increase in the concentration gradient. Both of these factors are important for sensor performance; the equilibrium sce- nario sets the limit of detection, but also the kinetics of the binding reaction govern the speed of detection. Thus, it is also worthwhile to consider other microfluidic approaches to enhance detection speed in addition to detection sensitivity. To a large extent, EGT sensors have worked with static reser- voirs, such as the one in Fig. 4(a), or droplets. 3,6-14,16-19,21-32,34-41 provide a basic understanding of how flow can Squires et al. 119 enhance sensor operation by confining the diffusion-dominated region to a boundary layer near the sensor surface, building on classical chemical engineering analysis. There are considerable opportunities for improving the mass flux to the EGT sensor surface by using the results of scaling theory or insights gained by numerical solutions to the convection-diffusion-reaction equa- 119 Naturally, any design optimization for the fluid flow will tions. be constrained by the size scales imposed by the printed electronics and the operating mechanism for the EGT. In particular, the size of the floating gate for the EGT must be large compared to the semi- conductor channel, which may pose challenges if that sensing pad needs to be confined within a thin microfluidic channel. Another approach to enhance the reactions at the surface is to promote mixing within the microchannel near the sensor surface. 119 herringbone mixer model in Fig. 10, One option is the which creates a chaotic flow pattern in the microchannel, 120 but a myriad of other passive micromixers that have been developed (see Ref. 121 for a recent review). In this context, it is important to keep in mind the goal of the mixer. Much of the literature on microflui- dic mixing focuses on the important problem of the homogeniza- tion of two inlet streams at different concentrations. This is not the challenge in sensing, since the initial inlet stream is already homo- geneous. Rather, the goal is to break up the depletion layer near the sensor surface 119 through convective transport from the bulk. In this respect, a herringbone mixer patterned onto the ceiling of the microchannel could be particularly effective at enhancing the sensor speed. Lamination-based mixing strategies based on spilt-and-recombining of streams, while effective for creating a homogeneous fluid, are not optimal for use in conjunction with the EGT sensor. Overall, we view enhancing transport to the sensor surface via fluid flow as the most promising avenue for improving EGT sensor performance via microfluidics. This opinion is based on the combi- nation of (i) the absence of much engineering in this direction to date and (ii) the extensive literature in microfluidics in this area for other applications. Of particular interest is the work done to opti- 122 mize depletion boundary layers in electrochemical reactors, which involve both the use of herringbone mixers and multiple inlets/outlets for replenishing depletion layers. VI. CONCLUDING REMARKS EGTs are an emerging platform for biosensing. This electronic-based method provides label-free, nonoptical detection of biomolecules from complex media 4,5 sample without any cleanup or preconcentration. The key advantage of EGTs with respect to their FET counterparts is their easy manufacturing by printing, which is both advantageous for the prototyping work needed to develop the technology and, in the longer term, for com- mercial production. Indeed, if the promise of printing electronics using the same roll-to-roll techniques used, for example, in newspa- per print are realized, this would lead to a dramatic reduction in cost and increase in throughput. Converting existing EGT sensors on silicon or glass onto flexible substrates could combine the porta- bility of paper microfluidic devices 123 with even more sophisticated 124 electronics than existing electrochemical paper sensors, poten- tially enabling a wealth of new applications. As an emerging sensing area, much of the work to date has focused on the electronics side of the EGT and proof-of-principle experimentation. The time is ripe to deploy the microfluidics toolbox to convert these prototype sensors into automated, high precision systems. We have identified here the low-hanging fruit that would come from multiplexing, sample preconcentration, and controlling transport to the surface. This is by no means an exhaus- tive list of possible ways in which microfluidics can improve EGT biosensors, and there is a wealth of knowledge in microfluidic sensors in other contexts that can be translated to the EGT plat- form. In general, printed electronics is a promising route for inte- gration with microfluidics, since the electronic platforms tend to use planar layouts with length scales in the hundred micrometer range that are ideally suited for microfluidic integration. We would be remiss if we concluded our discourse without a few comments on EGT detection in general, beyond those that are likely to be remedied by the microfluidic solutions discussed here. There are some improvements on the device side that are relatively straightforward. For example, our EGT biosensors could employ higher mobility semiconductors that can produce even higher 125 Similarly, the parasitic capacitance problem 33 needs to be gain. thoroughly understood and then remedied. This detective work will require careful, systematic experimentation, but it is likely a solv- able problem using existing techniques. We also see two major out- standing challenges in EGT detection in general that do not have straightforward, generic solutions. The first major challenge is EGT-based detection of small, neutral analytes. Owing to their small size relative to an antibody and the sparseness of the capture agents on the surface, such mole- cules are unlikely to create measurable changes in the capacitance C2 in Eq. (4). One possible solution is the use of shape-changing DNA aptamers, following recent work with these molecules in con- ventional ChemFETs. 2 9 this approach, binding of the neutral In molecules induces a change in the amount of DNA proximate to the surface and thus affects the term △⌀ in Eq. (4), not only the capacitance C2. Shape-changing aptamers certainly can address the problem, but their use is limited because it is not obvious that such aptamers can be identified for all relevant targets. A generic solu- tion to the small neutral molecule problem would have broad appli- cability, as there are a range of medically relevant targets (e.g., cortisol126,127) that fall within this class of analytes. The second major challenge is the detection of small charged molecules. It is clear that charges located proximate to the surface will affect △⌀, as evidenced by our work with SAMs of MUA. 34 However, an oft-cited problem with transistor-based detection is that charge detection is not operable outside the Debye layer, which is circa 1 nm in typical biological solutions. A number of possible solutions to this problem have appeared in the FET bio- sensor literature, including using antibody fragments 128,129 or self- hybridizing DNA aptamers 130 reduce the capture agent size, employing high136 frequency gate voltages 131 quickly pulsing the or gate voltage to avoid the formation of the static Debye layer on the measurement time, or the use of a porous poly(ethylene glycol) (PEG) layer at the sensor surface. 81,137-139 The latter approach is especially attractive since PEG can also prevent nonspe- cific adsorption to the sensor surface. Initial reports for this strategy proposed that the PEG layer creates a region of lower dielectric constant and thus extends the Debye length. However, a recent analysis of the experimental data 140 suggests that the key effect is the formation of a Donnan equilibrium for the antibody/antigen within the PEG layer, which leads to a different decay length and provides an interesting analogy with the capacitive sensing mecha- nism for EGTs proposed by Palazzo et al. 17 While we have identified material-based and electronic-based solutions that might be translated from FETs to EGTs for both of these key challenges, it is worthwhile to contemplate whether microfluidics offers novel solutions that are orthogonal to approaches based on the electronics design or capture agent chem- istry. Such flow-based solutions would not only improve EGT detection but could be translated broadly to all transistor-based detection schemes. ACKNOWLEDGMENTS This work was supported by the Michael H. Baker Family Foundation. Demetra Z. Adrahtas was supported by a Biotechnology Training (Grant No. NIH T32GM008347). References: 1M. Schena, D. Shalon, R. W. Davis, and P. 0. Brown, Science 270, 467 (1995). 2J. N. Anker, W. P. Hall, 0. Lyandres, N. C. Shah, J. Zhao, and R. P. van Duyne, Nat. Mater. 7, 442 (2008). 3S. P. White, K. D. Dorfman, and C. D. Frisbie, Anal. Chem. 87, 1861 (2015). 4S. P. White, S. Sreevatsan, C. D. Frisbie, and K. D. Dorfman, ACS Sens. 1, 1213 (2016). 5S. P. White, C. D. Frisbie, and K. D. Dorfman, ACS Sens. 3, 395 (2018). 6Z. Zhu, J. T. Mabeck, C. Zhu, N. C. Cady, C. A. Batt, and G. G. Malliaras, Chem. Commun. 2004, 1556. 7D. A. Bernards, D. J. Macaya, M. Nikolou, J. A. DeFranco, S. Takamatsu, and G. G. Malliaras, J. Mater. Chem. 18, 116 (2008). 8N. Y. Shim, D. A. Bernards, D. J. Macaya, J. A. DeFranco, M. Nikolou, R. M. Owens, and G. G. Malliaras, Sensors 9, 9896 (2009). 9Y. Ohno, K. Maehashi, Y. Yamashiro, and K. Matsumoto, Nano Lett. 9, 3318 (2009). 10F. Buth, A. Donner, M. Sachsenhauser, M. Stutzmann, and J. A. Garrido, Adv. Mater. 24, 4511 (2012). 11R. X. He, M. Zhang, F. Tan, P. H. M. Leung, X. Zhao, H. L. W. Chan, M. Yang, and F. Yan, J. Mater. Chem. 22, 22072 (2012). 12C. Suspene, B. Piro, S. Reisberg, M. Pham, H. Toss, M. Berggren, A. Yassar, and G. Horowitz, J. Mater. Chem. B 1, 2090 (2013). 13S. Casalini, F. Leonardi, T. Cramer, and F. Biscarini, Org. Electron. 14, 156 (2013). 14M. Magliulo, A. Mallardi, M. Y. Mulla, S. Cotrone, B. R. Pistillo, P. Favia, I. Vikholm-Lundin, G. Palazzo, and L. Torsi, Adv. Mater. 25, 2090 (2013). 15K. Schmoltner, J. Kofler, A. Klug, and E. J. W. List-Kratochvil, Adv. Mater. 25, 6895 (2013). 16E. Bandiello, M. Sessolo, and H. J. Bolink, J. Mater. Chem. C 2, 10277 (2014). 17G. Palazzo, D. de Tullio, M. Magliulo, A. Mallardi, F. Intranuovo, M. Y. Mulla, P. Favia, I. Vikholm-Lundin, and L. Torsi, Adv. Mater. 27, 911 (2015). 18E. Bihar, Y. Deng, T. Miyake, M. Saadaoui, G. G. Malliaras, and M. Rolandi, Sci. Rep. 6, 27582 (2016). 19M. Magliulo, D. De Tullio, I. Vikholm-Lundin, W. M. Albers, T. Munter, K. Manoli, G. Palazzo, and L. Torsi, Anal. Bioanal. Chem. 408, 3943 (2016). 20A. M. Pappa, V. F. Curto, M. Braendlein, X. Strakosas, M. J. Donahue, M. Fiocchi, G. G. Malliaras, and R. M. Owens, Adv. Healthc. Mater. 5, 2295 21Z. Hao, Y. Zhu, X. Wang, P. G. Rotti, C. DiMarco, S. R. Tyler, X. Zhao, J. F. Engelhardt, J. Hone, and Q. Lin, ACS Appl. Mater. Interfaces 9, 27504 (2017). 22T. Minamiki, Y. Hashima, Y. Sasaki, and T. Minami, Chem. Commun. 54, 6907 (2018). 23A. M. Pappa, D. Ohayon, A. Giovannitti, I. P. Maria, A. Savva, I. Uguz, J. Rivnay, I. McCulloch, R. M. Owens, and S. Inal, Sci. Adv. 4, eaat0911 (2018). 24N. Saraf, R. E. Woods, M. Peppler, and S. Seal, Biosens. Bioelectron. 117, 40 (2018). 25W. Hai, T. Goda, H. Takeuchi, S. Yamaoka, Y. Horiguchi, A. Matsumoto, and Y. Miyahara, Sens. Actuators B 260, 635 (2018). 26p. Seshadri, K. Manoli, N. Schneiderhan-Marra, U. Anthes, P. Wierzchowiec, K. Bonrad, C. Di Franco, and L. Torsi, Biosens. Bioelectron. 104, 113 (2018). 27L. Chen, Y. Fu, N. Wang, A. Yang, Y. Li, J. Wu, H. Ju, and F. Yan, ACS Appl. Mater. Interfaces 10, 18470 (2018). 28E. Macchia, K. Manoli, B. Holzer, C. Di Franco, M. Ghittorelli, F. Torricelli, D. Alberga, G. F. Mangiatordi, G. Palazzo, G. Scamarcio, and L. Torsi, Nat. Commun. 9, 3223 (2018). 29N. Nakatsuka, K. A. Yang, J. M. Abendroth, K. M. Cheung, X. Xu, H. Yang, C. Zhao, B. Zhu, Y. S. Rim, Y. Yang, P. S. Weiss, M. N. Stojanovic, and A. M. Andrews, Science 362, 319 (2018). 30R. Campos, J. Borme, J. R. Guerreiro, G. Machado, M. F. Cerqueira, D. Y. Pertovykj, and P. Alpuim, ACS Sens. 4, 286 (2019). 31E. Macchia, K. Manoli, B. Holzer, C. Di Franco, R. A. Picca, N. Cioffi, G. Scamarcio, G. Palazzo, and L. Torsi, Anal. Bioanal. Chem. 411, 4899 (2019). 32J. Liu, X. Chen, Q. Wan, M. Xiao, D. Zhong, W. Sun, G. Zhang, and Z. Zhang, Nano Lett. 19, 1437 (2019). 33S. P. White, K. D. Dorfman, and C. D. Frisbie, J. Phys. Chem. C 120, 108 34M. S. Thomas, S. P. White, K. D. Dorfman, and C. D. Frisbie, J. Phys. Chem. Lett. 9, 1335 (2018). 35p. Lin, F. Yan, and H. L. W. Chan, ACS Appl. Mater. Interfaces 2, 1637 (2010). 36H. Toss, B. Suspene, C. Piro, A. Yassar, X. Crispin, L. Kergoat, M. Pham, and M. Berggren, Org. Electron. 15, 2420 (2014). 37 A. Casalini, A. C. Dumitru, F. Leonardi, C. A. Bortolotti, E. T. Herruzo, A. Campana, R. F. de Oliveira, T. Cramer, R. Garcia, and F. Biscarni, ACS Nano 9, 5051 (2015). 38M. Berto, S. Casalini, M. Di Lauro, S. L. Marasso, M. Cocuzza, D. Perrone, M. Pinti, A. Cossarizza, C. F. Pirri, D. T. Simon, M. Berggren, F. Zerbetto, C. A. Bortolotti, and F. Biscarini, Anal. Chem. 88, 12330 (2016). 39 Q. Zhang, F. Leonardi, S. Casalini, I. Temino, and M. Mas-Torrent, Sci. Rep. 6, 39623 (2016). 40S. Okuda, T. Ono, Y. Kanai, T. Ikuta, M. Shimatani, S. Ogawa, K. Maehashi, K. Inoue, and K. Matsumoto, ACS Sens. 3, 200 (2018). 41 M. Sensi, M. Berto, A. Candini, A. Liscio, A. Cossarizza, V. Beni, F. Biscarini, and C. A. Bortolotti, ACS Omega 4, 5374 (2019). 42M. Kaisti, Biosens. Bioelectron. 98, 437 (2018). 43J. Rivnay, S. Inal, A. Salleo, R. M. Owens, M. Berggren, and G. G. Malliaras, Nat. Rev. Mater. 3, 17086 (2018). 44L. M. Bai, C. G. Elosegui, W. Q. Li, P. Yu, J. J. Fei, and L. Q. Mao, Front. Chem. 7, 313 (2019). 45H. Li, W. Shi, J. Song, H. J. Jang, J. Dailey, J. Yu, and H. E. Katz, Chem. Rev. 119, 3 (2019). 46p. Bergveld, IEEE Trans. Biomed. Eng. BME-17, 70 (1970). 47p. Bergveld, IEEE Trans. Biomed. Eng. 19, 342 (1972). 48 C. Toumazou, P. Georgiou, and P. Bergveld, Electron. Lett. 47, S7 (2011). 49S. Caras and J. Janata, Anal. Chem. 52, 1935 (1980). 50J. Janata, Electroanalysis 16, 1831 (2004). 51S. H. Kim, K. Hong, W. Xie, K. H. Lee, S. Zhang, T. P. Lodge, and C. D. Frisbie, Adv. Mater. 25, 1822 (2013). 52p. Bergveld, Sens. Actuators B 88, 1 (2003). 53J. van der Spiegel, I. Lauks, P. Chan, and D. Babic, Sens. Actuators 4, 291 (1983). 54S. Mao, G. Lu, K. Yu, Z. Bo, and J. Chen, Adv. Mater. 22, 3521 (2010). 55J. M. Kim, S. K. Jha, R. Chand, D. H. Lee, and Y. S. Kim, Biosens. Bioelectron. 26, 2264 (2011). 56J. Hagen, W. Lyon, Y. Chushak, M. Tomczak, R. Naik, M. Stone, and N. Kelley-Loughnane, ACS Chem. Neurosci. 4, 444 (2013). 57M. L. Hammock, 0. Knopfmacher, B. D. Naab, J. B. H. Tok, and Z. Bao, ACS Nano 7, 3970 (2013). 58H. Park, G. Han, S. W. Lee, H. Lee, S. H. Jeong, M. Naqi, A. AlMutairi, Y. J. Kim, J. Lee, W. Kim, S. Kim, Y. Yoon, and G. Yoo, ACS Appl. Mater. Interfaces 9, 43490 (2017). 59H. W. Lee, D. Kang, J. H. Cho, S. Lee, D. Jun, and J. Park, ACS Appl. Mater. Interfaces 10, 17369 (2018). 60p. Bergveld, Sens. Actuators 1, 17 (1981). 61K. McLaughlin, A. Dickson, S. B. Weisberg, K. Coale, V. Elrod, C. Hunter, K. S. Johnson, S. Kram, R. Kudela, T. Martz, K. Negrey, U. Passow, F. Shaughnessy, J. E. Smith, D. Tadesse, L. Washburn, and K. R. Weis, Reg. Stud. Mar. Sci. 12, 11 (2017). 62J. Kiumra, N. Ito, T. Kuriyama, M. Kikuchi, T. Arai, N. Negishi, and Y. Tomita, J. Electrochem. Soc. 136, 1744 (1989). 63X. L. Luo, J. J. Xu, W. Zhao, and H. Y. Chen, Sens. Actuators B 97, 249 (2004). 64T. Sakata, H. Sugimoto, and A. Saito, Anal. Chem. 90, 12731 (2018). 65S. Martinoia, N. Rosso, M. Grattarola, L. Lorenzelli, B. Margesin, and M. Zen, Biosens. Bioelectron. 16, 1043 (2001). 66F. Bettaieb, L. Ponsonnet, P. Lejeune, H. B. Ouada, C. Martelet, A. Bakhrouf, N. Jaffrezic-Renault, and A. Othmane, Bioelectrochem. 71, 118 (2007). 670. Kutova, M. Dusheiko, N. I. Klyui, and V. A. Skryshevsky, Microelectron. Eng. 215, 110993 (2019). 68S. Nakata, T. Arie, S. Akita, and K. Takei, ACS Sens. 2, 443 (2017). 69J. M. Rothberg, W. Hinz, T. M. Rearick, J. Schultz, W. Mileski, M. Davey, J. H. Leamon, K. Johnson, M. J. Milgrew, M. Edwards, J. Hoon, J. F. Simons, D. Marran, J. W. Myers, J. F. Davidson, A. Branting, J. R. Nobile, B. P. Puc, D. Light, T. A. Clark, M. Humber, J. T. Branciforte, I. B. Stoner, S. E. Cawley, M. Lyons, Y. Fu, N. Homer, M. Sedova, X. Miao, B. Reed, J. Sabina, E. Feierstein, M. Schorn, M. Alanjary, E. Dimalanta, D. Dressman, R. Kasinskas, T. Sokolsky, J. A. Fidanza, E. Namsaraev, K. J. McKernan, A. Williams, G. T. Roth, and J. Bustillo, Nature 475, 348 (2011). 70N. H. Al-Hardan, M. A. Abdul Hamid, N. M. Ahmed, A. Jalar, R. Shamsudin, N. K. Othman, L. Kar Keng, W. Chiu, and H. N. Al-Rawi, Sensors 16, 839 71L. T. Yin, J. C. Chou, W. Y. Chung, T. P. Sun, and S. K. Hsiung, Sens. Actuators B 71, 106 (2000). 72p. D. Batista and M. Mulato, Appl. Phys. Lett. 87, 143508 (2005). 73C. P. Chen, A. Ganguly, C. Y. Lu, T. Y. Chen, C. C. Kuo, R. S. Chen, W. H. Tu, W. B. Fishcer, K. H. Chen, and L. C. Chen, Anal. Chem. 83, 1938 (2011). 74T. Sakata, S. Matsumoto, Y. Nakajima, and Y. Miyahara, Jpn. J. Appl. Phys. 44, 2860 (2005). 75M. Kamahori, Y. Ishige, and M. Shimoda, Biosens. Bioelectron. 22, 3080 (2007). 76Q. Xue, C. Bian, J. Tong, J. Sun, H. Zhang, and S. Xia, Sens. Actuators A 169, 282 (2011). 77T. Goda and Y. Miyahara, Biosens. Bioelectron. 45, 89 (2013). 78W. Guan, X. Duan, and M. A. Reed, Biosens. Bioelectron. 51, 225 (2014). 79N. Aliakbarinodehi, P. Jolly, N. Bhalla, A. Miodek, G. de Micheli, P. Estrela, and S. Carrara, Sci. Rep. 7, 44409 (2017). 80 A. Tarasov, D. W. Gray, M.-Y. Tsai, N. Sheilds, A. Montrose, N. Creedon, P. Lovera, A. O\\'Riordan, M. H. Mooney, and E. M. Vogel, Biosens. Bioelectron. 79, 669 (2016). 81�. Guti�rrez-Sanz, N. M. Andoy, M. S. Filipiak, N. Haustein, and A. Tarasov, ACS Sens. 2, 1278 (2017). 82S. Zafar, M. Lu, and A. Jagtiani, Sci. Rep. 7, 41430 (2017). 83J. H. Cho, J. Lee, Y. Xia, B. Kim, Y. He, M. J. Renn, T. P. Lodge, and C. D. Frisbie, Nat. Mater. 7, 900 (2008). 84B. Tang, S. P. White, C. D. Frisbie, and T. P. Lodge, Macromolecules 48, 4942 (2015). 85D. Khodagholy, J. Rivnay, M. Sessolo, M. Gurfinkel, P. Leleux, L. H. Jimison, E. Stavrinidou, T. Herve, S. Sanaur, R. M. Owens, and G. G. Malliaras, Nat. Commun. 4, 2133 (2013). 86F. Z. Bidoky, B. Tang, R. Ma, K. S. Jochem, W. J. Hyun, D. Song, S. J. Koester, T. P. Lodge, and C. D. Frisbie, Adv. Funct. Mater. 29, 1902028 (2019). 87R. Abbel, Y. Galagan, and P. Groen, Adv. Eng. Mater. 20, 1701190 88 A. C. Arias, J. D. MacKenzie, I. McChulloch, J. Rivnay, and A. Salleo, Chem. Rev. 110, 3 (2010). 89D. Tobjork and R. Osterbacka, Adv. Mater. 23, 1935 (2011). 90R. R. Sondergaard, M. Hosel, and F. C. Krebs, J. Polym. Sci. B Polym. Phys. 51, 16 (2013). 91Z. Taleat, A. Khoshroo, and M. Mazlou-Ardakani, Microchim. Acta 181, 865 92W. C. Mak, V. Beni, and A. P. F. Turner, TRAC Trends Anal. Chem. 79, 297 93L. Nayak, S. Mohanty, S. K. Nayak, and A. Ramadoss, J. Mater. Chem. C 7, 8771 (2019). 94A. C. Arias, J. Daniel, B. Krusor, S. Ready, V. Sholin, and R. Street, J. Soc. Inf. Display 15, 485 (2007). 95M. J. Ha, W. Zhang, D. Braga, M. J. Renn, C. H. Kim, and C. D. Frisbie, ACS Appl. Mater. Interfaces 5, 13198 (2013). 96D. C. Duffy, J. C. McDonald, 0. J. A. Schueller, and G. M. Whitesides, Anal. Chem. 70, 4974 (1998). 97G. Comina, A. Suska, and D. Filppini, Lab Chip 14, 424 (2014). 98K. Kamei, Y. Mashimo, Y. Koyama, C. Fockenberg, M. Nakashima, M. Nakajima, J. Li, and Y. Chen, Biomed. Microdev. 17, 36 (2015). 99Y. Hwang, 0. H. Paydar, and R. N. Candler, Sens. Actuators A 226, 137 100H. N. Chan, Y. Chen, Y. Shu, Y. Chen, Q. Tian, and H. Wu, Microfluid. Nanofluid. 19, 9 (2015). 101B. Y. Ahn, E. B. Duoss, M. J. Motala, X. Guo, S. I. Park, Y. Xiong, J. Yoon, R. G. Nuzzo, J. A. Rogers, and J. A. Lewis, Science 323, 1590 (2009). 102S. H. Kim, K. Hong, K. H. Lee, and C. D. Frisbie, ACS Appl. Mater. Interfaces 5, 6580 (2013). 103R. P. Gandhiraman, V. Jayan, J.-W. Han, B. Chen, J. E. Koehne, and M. Meyyappan, ACS Appl. Mater. Interfaces 6, 20860 (2014). 104M. Smith, Y. S. Choi, C. Boughey, and S. Kar-Narayan, Flex. Print. Electron. 2, 015004 (2017). 105S. Kahn, T. P. Nguyen, M. Lubej, L. Thiery, P. Vairac, and D. Briand, Microelectron. Eng. 194, 71 (2018). 106M. T. Rahaman, C. Y. Cheng, B. Karagoz, M. Renn, M. Schrandt, A. Gellman, and R. Panat, ACS Appl. Nano Mater. 2, 3280 (2019). 107N. G. Di Novo, E. Cantu, S. Tonello, E. Sardini, and M. Serpelloni, Sensors 19, 1842 (2019). 108M. A. Rampi, 0. J. A. Schueller, and G. M. Whitesides, Appl. Phys. Lett. 72, 1781 (1998). 109T. Kakiuchi, M. Iida, S. Imabayashi, and K. Niki, Langmuir 16, 5397 (2000). 110E. A. Lamont, L. He, K. Warriner, T. P. Labuza, and S. Sreevatsan, Analyst 136, 3884 (2011). 111M. S. Thomas, K. D. Dorfman, and C. D. Frisbie, Flex. Print. Electron. 4, 044001 (2019). 112E. Garcia, M. Llorente, A. Hernando, R. Kieffer, H. Wieser, and E. Mendez, Eur. J. Gastroenterol. Hepatol. 17, 529 (2005). 113S. Amaya Gonzalez, N. de Los Santos Alvarez, A. J. Miranda Ordieres, and M. J. Lobo Castanon, Anal. Chem. 86, 2733 (2014). 114R. Hochegger, W. Mayer, and M. Prochaska, Foods 4, 654 (2015). 115T. Thorsen, S. J. Merkl, and S. R. Quake, Science 298, 580 (2002). 116C. Eid and J. G. Santiago, Lab Chip 18, 11 (2018). 117F. Paratore, T. Z. Kalman, T. Rosenfeld, G. V. Kaigala, and M. Bercovici, Anal. Chem. 89, 7373 (2017). 118A. Rogacs, L. A. Marshall, and J. G. Santiago, J. Chromatogr. A 1335, 105 119T. M. Squires, R. J. Messinger, and S. R. Manalis, Nat. Biotechnol. 26, 417 (2008). 120A. D. Stroock, S. K. W. Dertinger, A. Ajdari, I. Mezic, H. A. Stone, and G. M. Whitesides, Science 295, 647 (2002). 121C. Y. Lee, W. T. Wang, C. C. Liu, and L. M. Fu, Chem. Eng. J. 288, 146 122S. K. Yoon, G. W. Fichtl, and P. J. A. Kenis, Lab Chip 6, 1516 (2006). 123D. D. Liana, B. Raguse, J. J. Gooding, and E. Chow, Sensors 12, 11505 (2012). 124W. Dungchai, 0. Chailapakul, and C. S. Henry, Anal. Chem. 81, 5821 125K. Hong, S. H. Kim, K. H. Lee, and C. D. Frisbie, Adv. Mater. 24, 3413 126A. Kaushik, A. Vasudev, S. K. Arya, S. K. Pasha, and S. Bhansali, Biosens. Bioelectron. 53, 499 (2014). 1270. Parlak, S. T. Keene, A. Marais, V. F. Curto, and A. Salleo, Sci. Adv. 4, eaar2904 (2018). 128R. Elnathan, M. Kwiat, A. Pevzner, Y. Engel, L. Burstein, A. Khatchtourints, A. Lichtenstein, R. Kantaev, and F. Patolsky, Nano Lett. 12, 5245 (2012). 129S. Cheng, K. Hotani, S. Hideshima, S. Kuroiwa, T. Nakanishi, M. Hashimoto, Y. Mori, and T. Osaka, Materials 7, 2490 (2014). 130K. Maehashi, T. Katsura, K. Kerman, Y. Takamura, K. Matsumoto, and E. Tamiya, Anal. Chem. 79, 782 (2007). 131 G. S. Kulkarni and Z. Zhong, Nano Lett. 12, 719 (2012). 132C. H. Chu, I. Sarangadharan, A. Regmi, Y. W. Chen, C. P. Hsu, W. H. Chang, G. Y. Lee, J. I. Chyi, C. C. Chen, S. C. Shiesh, G. B. Lee, and Y. L. Wang, Sci. Rep. 7, 5256 (2017). 133J. Yang, P. Carey, F. Ren, Y. L. Wang, M. L. Good, S. Jang, M. A. Mastro, and S.J. Pearton, Appl. Phys. Lett. 111, 202104 (2017). 134I. Sarangadharan, A. Regmi, Y. W. Chen, C. P. Hsu, P. C. Chen, W. H. Chang, G. Y. Lee, J. I. Chyi, S. C. Shiesh, G. B. Lee, and Y. L. Wang, Biosens. Bioelectron. 100, 282 (2018). 135Y. W. Chen, T. Y. Tai, C. P. Hsu, I. Sarangadharan, A. K. Pulikkathodi, H. L. Wang, R. Sukesan, G. Y. Lee, J. I. Chyi, C. C. Chen, G. B. Lee, and Y. L. Wang, Sens. Actuators B 271, 110 (2018). scitation.org/journal/bmf 136T. Y. Tai, A. Sinha, I. Sarangadharan, A. K. Pulikkathodi, S. L. Wang, G. Y. Lee, J. I. Chyi, S. C. Shiesh, G. B. Lee, and Y. L. Wang, Anal. Chem. 91, 5953 (2019). 137N. Gao, W. Zhou, X. Jiang, G. Hong, T. M. Fu, and C. M. Lieber, Nano Lett. 15, 2143 (2015). 138N. Gao, T. Gao, X. Yang, X. Dai, W. Zhou, A. Zhang, and C. M. Lieber, Proc. Natl. Acad. Sci. U.S.A. 113, 14633 (2016). 139S. Ma, X. Li, Y. K. Lee, and A. Zhang, Biosens. Bioelectron. 117, 276 140N. Haustein, O. Guti�rrez-Sanz, and A. Tarasov, ACS Sens. 4, 874 (2019). 14, 011301-15'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717373587335
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 활동\n",
        "!nvidia-smi"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717082443956
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 txt 파일 경로를 모두 합침\n",
        "file_paths = []\n",
        "for path in before_paths:\n",
        "    file_paths.extend([os.path.join(path, file) for file in os.listdir(path) if file.endswith('.txt')])\n",
        "\n",
        "# JSON 파일에서 [\"contents\"] 추출\n",
        "json_contents = []\n",
        "for namefolder in os.listdir(json_paths[0]):\n",
        "    folder_path = os.path.join(json_paths[0], namefolder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.json'):\n",
        "                json_path = os.path.join(folder_path, file)\n",
        "                with open(json_path, 'r', encoding='utf-8') as f:\n",
        "                    data = json.load(f)\n",
        "                    json_contents.extend(data.get(\"contents\", []))\n",
        "\n",
        "# 기존 텍스트 파일 데이터셋 로드\n",
        "text_dataset = load_dataset('text', data_files=file_paths, cache_dir='/home/azureuser/cloudfiles/code/Users/hb.suh/cache')\n",
        "\n",
        "# JSON 파일에서 추출한 contents를 데이터셋으로 변환\n",
        "json_dataset = Dataset.from_dict({\"text\": json_contents})\n",
        "\n",
        "# text_path의 main_content 데이터를 데이터셋으로 변환\n",
        "main_content_dataset = Dataset.from_dict({\"text\": main_content_texts})\n",
        "\n",
        "# 텍스트와 JSON 데이터셋 병합\n",
        "combined_dataset = DatasetDict({\n",
        "    \"text_files\": text_dataset['train'],\n",
        "    \"json_contents\": json_dataset,\n",
        "    \"main_contents\": main_content_dataset\n",
        "})\n",
        "\n",
        "# 데이터셋 확인 (예시)\n",
        "print(combined_dataset)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DatasetDict({\n    text_files: Dataset({\n        features: ['text'],\n        num_rows: 944\n    })\n    json_contents: Dataset({\n        features: ['text'],\n        num_rows: 1193\n    })\n    main_contents: Dataset({\n        features: ['text'],\n        num_rows: 1484\n    })\n})\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717373594968
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로드\n",
        "\n",
        "from datasets import DatasetDict, Dataset\n",
        "\n",
        "# 각 데이터셋을 train과 test로 분할\n",
        "text_files_split = combined_dataset['text_files'].train_test_split(test_size=0.2)\n",
        "json_contents_split = combined_dataset['json_contents'].train_test_split(test_size=0.2)\n",
        "main_contents_split = combined_dataset['main_contents'].train_test_split(test_size=0.2)\n",
        "\n",
        "# 분할된 데이터셋을 다시 DatasetDict로 구성\n",
        "train_test_combined_dataset = DatasetDict({\n",
        "    'train': DatasetDict({\n",
        "        'text_files': text_files_split['train'],\n",
        "        'json_contents': json_contents_split['train'],\n",
        "        'main_contents': main_contents_split['train']\n",
        "    }),\n",
        "    'val': DatasetDict({\n",
        "        'text_files': text_files_split['test'],\n",
        "        'json_contents': json_contents_split['test'],\n",
        "        'main_contents': main_contents_split['test']\n",
        "    })\n",
        "})\n",
        "\n",
        "print(train_test_combined_dataset)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DatasetDict({\n    train: DatasetDict({\n        text_files: Dataset({\n            features: ['text'],\n            num_rows: 755\n        })\n        json_contents: Dataset({\n            features: ['text'],\n            num_rows: 954\n        })\n        main_contents: Dataset({\n            features: ['text'],\n            num_rows: 1187\n        })\n    })\n    val: DatasetDict({\n        text_files: Dataset({\n            features: ['text'],\n            num_rows: 189\n        })\n        json_contents: Dataset({\n            features: ['text'],\n            num_rows: 239\n        })\n        main_contents: Dataset({\n            features: ['text'],\n            num_rows: 297\n        })\n    })\n})\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717373595384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 파일 경로를 파일로 저장\n",
        "\n",
        "merged_file_path = \"/home/azureuser/cloudfiles/code/Users/hb.suh/merged_data.txt\"\n",
        "with open(merged_file_path, 'w', encoding='utf-8') as f:\n",
        "    # text_files 데이터셋 저장\n",
        "    for item in combined_dataset['text_files']:\n",
        "        text = item['text']\n",
        "        if isinstance(text, dict):\n",
        "            text = json.dumps(text)\n",
        "        f.write(text + '\\n')\n",
        "    \n",
        "    # json_contents 데이터셋 저장\n",
        "    for item in combined_dataset['json_contents']:\n",
        "        text = item['text']\n",
        "        if isinstance(text, dict):\n",
        "            text = json.dumps(text)\n",
        "        f.write(text + '\\n')\n",
        "    \n",
        "    # main_contents 데이터셋 저장\n",
        "    for item in combined_dataset['main_contents']:\n",
        "        text = item['text']\n",
        "        if isinstance(text, dict):\n",
        "            text = json.dumps(text)\n",
        "        f.write(text + '\\n')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717373597952
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "# BertWordPieceTokenizer 인스턴스 생성\n",
        "tokenizer = BertWordPieceTokenizer(clean_text=True, handle_chinese_chars=True, strip_accents=False, lowercase=False, wordpieces_prefix=\"##\")\n",
        "\n",
        "# 훈련하기\n",
        "tokenizer.train(\n",
        "    merged_file_path,\n",
        "    vocab_size=30000,\n",
        "    min_frequency=3,\n",
        "    show_progress=True,\n",
        "    special_tokens = [\"[PAD]\", \"[CLS]\", \"[UNK]\", \"[SEP]\", \"[MASK]\"],\n",
        "    wordpieces_prefix=\"##\",\n",
        ")\n",
        "\n",
        "# 저장할 디렉토리 경로    \n",
        "save_path = \"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/trained_tokenizer/0530_AddData_bertwordpiece\"\n",
        "\n",
        "# 디렉토리가 없으면 생성\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "# 토크나이저 모델 저장\n",
        "tokenizer.save_model(save_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "['/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/trained_tokenizer/0530_AddData_bertwordpiece/vocab.txt']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717140559359
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 토크나이저 로드\n",
        "new_tokenizer = BertTokenizerFast.from_pretrained('beomi/kcbert-base')\n",
        "model = BertForMaskedLM.from_pretrained('beomi/kcbert-base')\n",
        "len(new_tokenizer)\n",
        "\n",
        "new_tokens_added = 0\n",
        "new_vocab = {}  # 새로운 토큰과 아이디를 담을 딕셔너리\n",
        "\n",
        "#path = \"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/trained_tokenizer/0527test_bertwordpiece/vocab.txt\"\n",
        "path = os.path.join(save_path, \"vocab.txt\")\n",
        "# 기존의 토크나이저 vocab에서 새로운 토큰들을 제외하고 아이디 부여\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        token = line.strip()  # 줄바꿈 문자를 제거하여 토큰만 가져옴\n",
        "        if token not in new_tokenizer.get_vocab():\n",
        "            new_tokenizer.add_tokens(token)\n",
        "            new_tokens_added += 1\n",
        "            new_vocab[token] = len(new_tokenizer) - 1  # 새로운 토큰에 새로운 아이디 부여\n",
        "\n",
        "        else:\n",
        "            # 토큰이 이미 존재하면, 기존 ID 사용\n",
        "            new_vocab[token] = new_tokenizer.convert_tokens_to_ids(token)\n",
        "\n",
        "print(\"new_tokens_added : \", new_tokens_added)\n",
        "print(len(new_tokenizer))\n",
        "\n",
        "# 토크나이저 모델 파일 저장\n",
        "tokenizer_model_path = \"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/trained_tokenizer/0530_AddData_bertwordpiece\"\n",
        "new_tokenizer.save_pretrained(tokenizer_model_path,do_lower_case=False)\n",
        "\n",
        "len(new_tokenizer)\n",
        "\n",
        "print(f\"Added {new_tokens_added} new tokens\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "new_tokens_added :  939\n30939\nAdded 939 new tokens\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717140598322
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 데이터셋 토큰화\n",
        "\n",
        "# def tokenize_data(tokenizer, dataset):\n",
        "#     def tokenize_function(examples):\n",
        "#         # tokenizer의 결과에서 'input_ids'와 'attention_mask'만 반환하도록 수정 #128\n",
        "#         tokenized_output = tokenizer(examples['text'], max_length=300, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "#         return {'input_ids': tokenized_output['input_ids'], 'attention_mask': tokenized_output['attention_mask']}\n",
        "#     return dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "  \n",
        "\n",
        "# def resize_and_initialize_embeddings(model, tokenizer, old_tokenizer=None):\n",
        "#     # 모델의 원래 토큰 임베딩 크기\n",
        "#     original_num_tokens = model.config.vocab_size if old_tokenizer is None else len(old_tokenizer)\n",
        "    \n",
        "#     # 새 토크나이저에 따른 임베딩 크기 조정\n",
        "#     new_num_tokens = len(tokenizer)\n",
        "#     model.resize_token_embeddings(new_num_tokens)\n",
        "\n",
        "#     # 임베딩 레이어에 접근\n",
        "#     embeddings = model.get_input_embeddings()\n",
        "    \n",
        "#     # 새로운 토큰이 추가되었을 경우\n",
        "#     if new_num_tokens > original_num_tokens:\n",
        "#         # 기존 임베딩의 평균과 표준편차 계산\n",
        "#         with torch.no_grad():\n",
        "#             old_embeddings = embeddings.weight[:original_num_tokens]\n",
        "#             mean, std = old_embeddings.mean(dim=0), old_embeddings.std(dim=0)\n",
        "#             # 새로운 토큰의 임베딩 초기화\n",
        "#             new_embeddings = torch.randn(new_num_tokens - original_num_tokens, embeddings.embedding_dim)\n",
        "#             new_embeddings = mean + std * new_embeddings\n",
        "#             embeddings.weight[original_num_tokens:] = new_embeddings\n",
        "\n",
        "#     return model\n",
        "new_tokenizer = BertTokenizerFast.from_pretrained('beomi/kcbert-base')\n",
        "model = BertForMaskedLM.from_pretrained('beomi/kcbert-base')\n",
        "\n",
        "\n",
        "# 기존 가중치 freeze\n",
        "def resize_and_initialize_embeddings(model, tokenizer, old_tokenizer=None):\n",
        "    # 모델의 원래 토큰 임베딩 크기\n",
        "    original_num_tokens = model.config.vocab_size if old_tokenizer is None else len(old_tokenizer)\n",
        "    \n",
        "    # 새 토크나이저에 따른 임베딩 크기 조정\n",
        "    new_num_tokens = len(tokenizer)\n",
        "    model.resize_token_embeddings(new_num_tokens)\n",
        "\n",
        "    # 임베딩 레이어에 접근\n",
        "    embeddings = model.get_input_embeddings()\n",
        "    \n",
        "    # 기존 임베딩의 그라디언트 업데이트 비활성화\n",
        "    embeddings.weight.requires_grad = False\n",
        "\n",
        "    # 새로운 토큰이 추가되었을 경우\n",
        "    if new_num_tokens > original_num_tokens:\n",
        "        # 새로운 토큰의 임베딩만 그라디언트 업데이트 활성화\n",
        "        embeddings.weight[original_num_tokens:].requires_grad = True\n",
        "        \n",
        "        # 기존 임베딩의 평균과 표준편차 계산\n",
        "        with torch.no_grad():\n",
        "            old_embeddings = embeddings.weight[:original_num_tokens]\n",
        "            mean, std = old_embeddings.mean(dim=0), old_embeddings.std(dim=0)\n",
        "            # 새로운 토큰의 임베딩 초기화\n",
        "            new_embeddings = torch.randn(new_num_tokens - original_num_tokens, embeddings.embedding_dim, device=old_embeddings.device)\n",
        "            new_embeddings = mean + std * new_embeddings\n",
        "            embeddings.weight[original_num_tokens:].data = new_embeddings\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# model = BertForMaskedLM.from_pretrained('beomi/kcbert-base')\n",
        "# 드롭아웃 비율 조정\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, torch.nn.Dropout):\n",
        "        module.p = 0.3  # 드롭아웃 확률을 0.3으로 조정\n",
        "###############################################################\n",
        "after_add_Trained_Tokenizer = BertTokenizerFast.from_pretrained(\"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/trained_tokenizer/0530_AddData_bertwordpiece/\",do_lower_case=False)\n",
        "\n",
        "model = resize_and_initialize_embeddings(model, after_add_Trained_Tokenizer )\n",
        "print(len(after_add_Trained_Tokenizer))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "30939\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717373600602
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from torch.utils.data import DataLoader\n",
        "# from transformers import DataCollatorForLanguageModeling, AdamW, get_scheduler\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def train_model(model, train_dataset, valid_dataset, tokenizer, EPOCH, early_stopping_patience=None):\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     model.to(device)\n",
        "\n",
        "#     # Optimizer and learning rate scheduler setup\n",
        "#     optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
        "#     total_steps = len(train_dataset) * EPOCH\n",
        "\n",
        "#     scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
        "#                                                   base_lr=1e-6, \n",
        "#                                                   max_lr=1e-4,  # Adjusted max_lr\n",
        "#                                                   step_size_up=total_steps // 4,\n",
        "#                                                   step_size_down=total_steps - total_steps // 4,\n",
        "#                                                   mode='triangular',\n",
        "#                                                   cycle_momentum=False)\n",
        "\n",
        "#     data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
        "#     train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=data_collator)\n",
        "#     valid_loader = DataLoader(valid_dataset, batch_size=16, collate_fn=data_collator)\n",
        "\n",
        "#     model.train()\n",
        "\n",
        "#     train_losses = []\n",
        "#     valid_losses = []\n",
        "#     best_loss = float('inf')\n",
        "#     patience_counter = 0\n",
        "\n",
        "\n",
        "#     # 데이터 검증을 위한 간단한 함수\n",
        "#     def validate_data(batch):\n",
        "#         for k, v in batch.items():\n",
        "#             if torch.isnan(v).any() or torch.isinf(v).any():\n",
        "#                 print(f\"Invalid data in batch: {k}\")\n",
        "#                 return False\n",
        "#         return True\n",
        "\n",
        "\n",
        "#     for epoch in range(EPOCH):\n",
        "#         model.train()\n",
        "#         epoch_train_losses = []\n",
        "#         for batch in train_loader:\n",
        "#             batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "#             # 데이터 검증\n",
        "#             if not validate_data(batch):\n",
        "#                 continue\n",
        "\n",
        "#             outputs = model(**batch)\n",
        "#             loss = outputs.loss\n",
        "\n",
        "#             if torch.isnan(loss):\n",
        "#                 print(\"NaN detected, skipping the update\")\n",
        "#                 continue\n",
        "\n",
        "#             loss.backward()\n",
        "\n",
        "#             # Implementing gradient clipping\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "#             optimizer.step()\n",
        "#             scheduler.step()\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#             epoch_train_losses.append(loss.item())\n",
        "\n",
        "#         train_loss = sum(epoch_train_losses) / len(epoch_train_losses)\n",
        "#         train_losses.append(train_loss)\n",
        "\n",
        "#         # Validation phase\n",
        "#         model.eval()\n",
        "#         epoch_valid_losses = []\n",
        "#         with torch.no_grad():\n",
        "#             for batch in valid_loader:\n",
        "#                 batch = {k: v.to(device) for k, v in batch.items()}\n",
        "#                 outputs = model(**batch)\n",
        "#                 loss = outputs.loss\n",
        "\n",
        "#                 if torch.isnan(loss):\n",
        "#                     print(\"NaN detected in validation, skipping this batch\")\n",
        "#                     continue\n",
        "\n",
        "#                 epoch_valid_losses.append(loss.item())\n",
        "\n",
        "#         valid_loss = sum(epoch_valid_losses) / len(epoch_valid_losses)\n",
        "#         valid_losses.append(valid_loss)\n",
        "\n",
        "#         print(f\"Epoch {epoch + 1} completed, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Current LR: {scheduler.get_last_lr()[0]}\")\n",
        "\n",
        "#         # Early stopping logic\n",
        "#         if valid_loss < best_loss:\n",
        "#             best_loss = valid_loss\n",
        "#             patience_counter = 0\n",
        "#         else:\n",
        "#             patience_counter += 1\n",
        "\n",
        "#         if early_stopping_patience and patience_counter >= early_stopping_patience:\n",
        "#             print(f\"Early stopping at epoch {epoch + 1} as no improvement in validation loss.\")\n",
        "#             break\n",
        "\n",
        "#     # Plotting the training and validation loss trends\n",
        "#     plt.figure(figsize=(12, 6))\n",
        "#     plt.plot(train_losses, label='Training Loss')\n",
        "#     plt.plot(valid_losses, label='Validation Loss')\n",
        "#     plt.title('Training and Validation Loss Trends')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.ylabel('Loss')\n",
        "#     plt.legend()\n",
        "#     plt.grid(True)\n",
        "#     plt.show()\n",
        "\n",
        "#     return model\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717048550206
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_model(model, tokenizer, pretrained_model_name):\n",
        "\n",
        "    safe_model_name = pretrained_model_name.replace(\"/\", \"-\")\n",
        "    # 현재 날짜와 시간을 포함한 디렉토리 이름을 생성\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    directory = f\"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/MLM_trained_model/{safe_model_name}_CyclicLRtriangular-{timestamp}\"\n",
        "\n",
        "    # 디렉토리가 존재하지 않으면 생성\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    # 모델과 토크나이저를 사전 훈련된 디렉토리에 저장\n",
        "    model.save_pretrained(directory)\n",
        "    tokenizer.save_pretrained(directory)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717373600792
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = train_test_combined_dataset['train']\n",
        "\n",
        "# def tokenize_data(tokenizer, dataset):\n",
        "#     def tokenize_function(examples):\n",
        "#         # 리스트 형식의 텍스트 입력을 처리하도록 수정\n",
        "#         if isinstance(examples['text'], list):\n",
        "#             examples['text'] = [str(x) for x in examples['text']]\n",
        "#         else:\n",
        "#             examples['text'] = [str(examples['text'])]\n",
        "\n",
        "#         tokenized_output = tokenizer(examples['text'], max_length=300, truncation=True, padding=\"max_length\")\n",
        "#         return {'input_ids': tokenized_output['input_ids'], 'attention_mask': tokenized_output['attention_mask']}\n",
        "    \n",
        "#     return dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "\n",
        "# train_tokenized_datasets = tokenize_data(after_add_Trained_Tokenizer, train_dataset)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717074313523
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_dataset = train_test_combined_dataset['valid']\n",
        "# val_tokenized_datasets = tokenize_data(after_add_Trained_Tokenizer, val_dataset)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717074313535
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_tokenized_datasets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717074312822
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_combined_dataset"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "DatasetDict({\n    train: DatasetDict({\n        text_files: Dataset({\n            features: ['text'],\n            num_rows: 755\n        })\n        json_contents: Dataset({\n            features: ['text'],\n            num_rows: 932\n        })\n        main_contents: Dataset({\n            features: ['text'],\n            num_rows: 1187\n        })\n    })\n    val: DatasetDict({\n        text_files: Dataset({\n            features: ['text'],\n            num_rows: 189\n        })\n        json_contents: Dataset({\n            features: ['text'],\n            num_rows: 233\n        })\n        main_contents: Dataset({\n            features: ['text'],\n            num_rows: 297\n        })\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717079605354
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(tokenizer, dataset):\n",
        "    def tokenize_function(examples):\n",
        "        if isinstance(examples['text'], list):\n",
        "            examples['text'] = [str(x) for x in examples['text']]\n",
        "        else:\n",
        "            examples['text'] = [str(examples['text'])]\n",
        "        tokenized_output = tokenizer(examples['text'], max_length=300, truncation=True, padding=\"max_length\")\n",
        "        return {'input_ids': tokenized_output['input_ids'], 'attention_mask': tokenized_output['attention_mask']}\n",
        "    \n",
        "    return dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "\n",
        "# train과 validation 데이터셋을 개별적으로 토큰화\n",
        "train_test_combined_dataset = DatasetDict({\n",
        "    'train': {\n",
        "        'text_files': tokenize_data(after_add_Trained_Tokenizer, train_test_combined_dataset['train']['text_files']),\n",
        "        'json_contents': tokenize_data(after_add_Trained_Tokenizer, train_test_combined_dataset['train']['json_contents']),\n",
        "        'main_contents': tokenize_data(after_add_Trained_Tokenizer, train_test_combined_dataset['train']['main_contents'])\n",
        "    },\n",
        "    'valid': {\n",
        "        'text_files': tokenize_data(after_add_Trained_Tokenizer, train_test_combined_dataset['val']['text_files']),\n",
        "        'json_contents': tokenize_data(after_add_Trained_Tokenizer, train_test_combined_dataset['val']['json_contents']),\n",
        "        'main_contents': tokenize_data(after_add_Trained_Tokenizer, train_test_combined_dataset['val']['main_contents'])\n",
        "    }\n",
        "})\n",
        "\n",
        "\n",
        "from datasets import concatenate_datasets\n",
        "# 모든 데이터셋을 하나로 병합\n",
        "train_dataset = concatenate_datasets([\n",
        "    train_test_combined_dataset['train']['text_files'],\n",
        "    train_test_combined_dataset['train']['json_contents'],\n",
        "    train_test_combined_dataset['train']['main_contents']\n",
        "])\n",
        "val_dataset = concatenate_datasets([\n",
        "    train_test_combined_dataset['valid']['text_files'],\n",
        "    train_test_combined_dataset['valid']['json_contents'],\n",
        "    train_test_combined_dataset['valid']['main_contents']\n",
        "])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Map: 100%|██████████| 755/755 [00:29<00:00, 25.64 examples/s]\nMap: 100%|██████████| 954/954 [00:01<00:00, 740.23 examples/s]\nMap: 100%|██████████| 1187/1187 [00:18<00:00, 63.53 examples/s]\nMap: 100%|██████████| 189/189 [00:00<00:00, 487.78 examples/s]\nMap: 100%|██████████| 239/239 [00:00<00:00, 749.73 examples/s]\nMap: 100%|██████████| 297/297 [00:04<00:00, 66.32 examples/s]\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717373655658
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataset, valid_dataset, tokenizer, EPOCH, early_stopping_patience=None):\n",
        "    try:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(torch.cuda.is_available())\n",
        "        model.to(device)\n",
        "        print(device)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"CUDA error: {e}\")\n",
        "        print(\"Falling back to CPU...\")\n",
        "        device = torch.device(\"cpu\")\n",
        "        model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
        "    total_steps = len(train_dataset) * EPOCH\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
        "                                                  base_lr=1e-6, \n",
        "                                                  max_lr=1e-5,  \n",
        "                                                  step_size_up=total_steps // 4,\n",
        "                                                  step_size_down=total_steps - total_steps // 4,\n",
        "                                                  mode='triangular',\n",
        "                                                  cycle_momentum=False)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=data_collator)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=16, collate_fn=data_collator)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_losses = []\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    def validate_data(batch):\n",
        "        for k, v in batch.items():\n",
        "            if torch.isnan(v).any() or torch.isinf(v).any():\n",
        "                print(f\"Invalid data in batch: {k}\")\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "        model.train()\n",
        "        epoch_train_losses = []\n",
        "        for batch in train_loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            if not validate_data(batch):\n",
        "                continue\n",
        "\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(\"NaN detected, skipping the update\")\n",
        "                continue\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            epoch_train_losses.append(loss.item())\n",
        "\n",
        "        train_loss = sum(epoch_train_losses) / len(epoch_train_losses)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        epoch_valid_losses = []\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_loader:\n",
        "                batch = {k: v.to(device) for k, v in batch.items()}\n",
        "                outputs = model(**batch)\n",
        "                loss = outputs.loss\n",
        "\n",
        "                if torch.isnan(loss):\n",
        "                    print(\"NaN detected in validation, skipping this batch\")\n",
        "                    continue\n",
        "\n",
        "                epoch_valid_losses.append(loss.item())\n",
        "\n",
        "        valid_loss = sum(epoch_valid_losses) / len(epoch_valid_losses)\n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} completed, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Current LR: {scheduler.get_last_lr()[0]}\")\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if early_stopping_patience and patience_counter >= early_stopping_patience:\n",
        "            print(f\"Early stopping at epoch {epoch + 1} as no improvement in validation loss.\")\n",
        "            break\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(valid_losses, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss Trends')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717373655974
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mon Jun  3 00:14:15 2024       \r\n+---------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\r\n|-----------------------------------------+----------------------+----------------------+\r\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                      |               MIG M. |\r\n|=========================================+======================+======================|\r\n|   0  Tesla V100-PCIE-16GB           Off | 00000001:00:00.0 Off |                  Off |\r\n| N/A   32C    P0              37W / 250W |  11342MiB / 16384MiB |      0%      Default |\r\n|                                         |                      |                  N/A |\r\n+-----------------------------------------+----------------------+----------------------+\r\n                                                                                         \r\n+---------------------------------------------------------------------------------------+\r\n| Processes:                                                                            |\r\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n|        ID   ID                                                             Usage      |\r\n|=======================================================================================|\r\n|    0   N/A  N/A      4096      C   /anaconda/envs/generation/bin/python       1988MiB |\r\n|    0   N/A  N/A    656741      C   .../envs/llm-rag-embeddings/bin/python     9350MiB |\r\n+---------------------------------------------------------------------------------------+\r\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717079256907
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 \n",
        "model = train_model(model, train_dataset, val_dataset, after_add_Trained_Tokenizer , 20, early_stopping_patience=5)\n",
        "\n",
        "print(len(after_add_Trained_Tokenizer))\n",
        "\n",
        "# 모델 저장\n",
        "save_model(model, after_add_Trained_Tokenizer, \"beomi/kcbert-base\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "True\ncuda\nEpoch 1 completed, Train Loss: 4.727162554777788, Valid Loss: 3.756145347719607, Current LR: 2.2375000000000175e-06\nEpoch 2 completed, Train Loss: 4.334030848181709, Valid Loss: 3.4686498279156894, Current LR: 3.4750000000000353e-06\nEpoch 3 completed, Train Loss: 4.050618487827027, Valid Loss: 3.211669333603071, Current LR: 4.7124999999999655e-06\nEpoch 4 completed, Train Loss: 3.829213365006842, Valid Loss: 3.074985944706461, Current LR: 5.949999999999983e-06\nEpoch 5 completed, Train Loss: 3.637079971271325, Valid Loss: 2.871929137603096, Current LR: 7.1875e-06\nEpoch 6 completed, Train Loss: 3.478320109910069, Valid Loss: 2.8221050163973933, Current LR: 8.425000000000018e-06\nEpoch 7 completed, Train Loss: 3.335305454981261, Valid Loss: 2.6903595302415932, Current LR: 9.662500000000037e-06\nEpoch 8 completed, Train Loss: 3.2114289643356155, Valid Loss: 2.6767838908278425, Current LR: 1.0899999999999967e-05\nEpoch 9 completed, Train Loss: 3.107893974082905, Valid Loss: 2.5223685451175855, Current LR: 1.2137499999999983e-05\nEpoch 10 completed, Train Loss: 3.0347288063217923, Valid Loss: 2.4911410938138547, Current LR: 1.3375000000000002e-05\nEpoch 11 completed, Train Loss: 2.928865296405982, Valid Loss: 2.389020432596621, Current LR: 1.461250000000002e-05\nEpoch 12 completed, Train Loss: 2.8551152588912796, Valid Loss: 2.3868902947591697, Current LR: 1.5850000000000036e-05\nEpoch 13 completed, Train Loss: 2.7998641966456206, Valid Loss: 2.3398554972980334, Current LR: 1.7087499999999968e-05\nEpoch 14 completed, Train Loss: 2.7245756644570367, Valid Loss: 2.2599779950535814, Current LR: 1.8324999999999985e-05\nEpoch 15 completed, Train Loss: 2.6639577585030656, Valid Loss: 2.2731136226135753, Current LR: 1.95625e-05\nEpoch 16 completed, Train Loss: 2.62812726800613, Valid Loss: 2.2046339835809623, Current LR: 2.080000000000002e-05\nEpoch 17 completed, Train Loss: 2.55872755353622, Valid Loss: 2.172044506539469, Current LR: 2.2037500000000038e-05\nEpoch 18 completed, Train Loss: 2.5318673150974083, Valid Loss: 2.1128314072671146, Current LR: 2.3274999999999966e-05\nEpoch 19 completed, Train Loss: 2.466315493399267, Valid Loss: 2.1174778756888015, Current LR: 2.4512499999999986e-05\nEpoch 20 completed, Train Loss: 2.4162776753388715, Valid Loss: 2.048411011695862, Current LR: 2.5750000000000002e-05\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "30939\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717377334964
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717057464760
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "@ model : kcBert-base\n",
        "- 기본 : 98 epoch, HITRATE : 0.079\n",
        "- 표준편차를 조정 : 30 epoch, HITRATE : 0.093\n",
        "- 기존 weights freeze : 20 epoch , HITRATE : 0.136295\n",
        "- 레퍼런스 코드 따라한 기본: 188 epoch , HITRATE : 0.07938\n",
        "- ( vocab추가 : 10000 ), vocab 정리, valid set 생성(과적합 탐지), (lr, optim 변경), 기존 weights freeze : 10 epoch HITRATE : 0.14977\n",
        "- ( vocab추가 : 30000 ) , 기존 weights freeze, (dropout : 0.3) : 26 epoch HITRATE : 0.10933\n",
        "- ( vocab추가 : 30000 ) , @@데이터 추가@@, 기존 weights freeze, (dropout : 0.3) : 100 epoch HITRATE : 0.1253\n",
        "- ( vocab추가 : 10000 ) , @@데이터 추가@@, 기존 weights freeze, (dropout : 0.3) : 100 epoch HITRATE :\n",
        "\n",
        "\n",
        "@ model : KcBert-v2023 \n",
        "- ( vocab추가 : 30000 총 79871 ) , 기존 weights freeze, (dropout : 0.3) : _epoch HITRATE : "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## for test"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰학습"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰 추가 후 최종 토크나이저"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "text = '  공정변수를 진공성형의 사출성형해석에 요인배치로써 공급부에 중요한 역할을 제공한다. '\n",
        "tokenizer =BertTokenizerFast.from_pretrained(\"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/trained_tokenizer/0508test_bertwordpiece/\",do_lower_case=False)\n",
        "# 텍스트 토큰화\n",
        "tokenized_output = tokenizer.encode(text, add_special_tokens=False)\n",
        "print(tokenized_output)\n",
        "print(\"tokenizer len:\",len(tokenizer))\n",
        "# 토큰화 결과 출력\n",
        "for output in tokenized_output:\n",
        "    decoded_output = tokenizer.decode(output)\n",
        "    print(\"Decoded Text:\", decoded_output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[34904, 31027, 33480, 30994, 2255, 31029, 17238, 14639, 11144, 15328, 10302, 17572, 13248, 8008, 17]\ntokenizer len: 36196\nDecoded Text: 공정변수를\nDecoded Text: 진공\nDecoded Text: 성형의\nDecoded Text: 사출성형해석\nDecoded Text: 에\nDecoded Text: 요인\nDecoded Text: 배치\nDecoded Text: ##로써\nDecoded Text: 공급\nDecoded Text: ##부에\nDecoded Text: 중요한\nDecoded Text: 역할을\nDecoded Text: 제공\nDecoded Text: ##한다\nDecoded Text: .\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715179613825
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "text = [\"공정변수가 진공성형의 사출성형해석에 요인배치로써 공급부에 중요한 역할을 제공한다.\"]\n",
        "tokenizer = BertTokenizer.from_pretrained('/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/trained_tokenizer/bertwordpiece', do_basic_tokenize=False)\n",
        "# 텍스트 토큰화\n",
        "tokenized_output = tokenizer.encode(str(text), add_special_tokens=True)\n",
        "print(tokenized_output)\n",
        "\n",
        "# 토큰화 결과 출력\n",
        "for output in tokenized_output:\n",
        "    decoded_output = tokenizer.decode(output, skip_special_tokens=True)\n",
        "    print(\"Decoded Text:\", decoded_output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[2, 1, 1, 1785, 4208, 4093, 4572, 4032, 27667, 1, 1, 10302, 17572, 1, 3]\nDecoded Text: [ C L S ]\nDecoded Text: [ U N K ]\nDecoded Text: [ U N K ]\nDecoded Text: 사\nDecoded Text: # # 출\nDecoded Text: # # 성\nDecoded Text: # # 형\nDecoded Text: # # 해\nDecoded Text: # # 석 에\nDecoded Text: [ U N K ]\nDecoded Text: [ U N K ]\nDecoded Text: 중 요 한\nDecoded Text: 역 할 을\nDecoded Text: [ U N K ]\nDecoded Text: [ S E P ]\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715046387913
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "text = '  공정변수를 진공성형의 사출성형해석에 요인배치로써 공급부에 중요한 역할을 제공한다. '\n",
        "tokenizer =BertTokenizerFast.from_pretrained(\"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/trained_tokenizer/0508test_bertwordpiece/\",do_lower_case=False)\n",
        "# 텍스트 토큰화\n",
        "tokenized_output = tokenizer.encode(text, add_special_tokens=False)\n",
        "print(tokenized_output)\n",
        "print(\"tokenizer len:\",len(tokenizer))\n",
        "# 토큰화 결과 출력\n",
        "for output in tokenized_output:\n",
        "    decoded_output = tokenizer.decode(output)\n",
        "    print(\"Decoded Text:\", decoded_output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[34904, 31027, 33480, 30994, 2255, 31029, 17238, 14639, 11144, 15328, 10302, 17572, 13248, 8008, 17]\ntokenizer len: 36196\nDecoded Text: 공정변수를\nDecoded Text: 진공\nDecoded Text: 성형의\nDecoded Text: 사출성형해석\nDecoded Text: 에\nDecoded Text: 요인\nDecoded Text: 배치\nDecoded Text: ##로써\nDecoded Text: 공급\nDecoded Text: ##부에\nDecoded Text: 중요한\nDecoded Text: 역할을\nDecoded Text: 제공\nDecoded Text: ##한다\nDecoded Text: .\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715176094596
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 새 토큰의 ID 확인\n",
        "token_id = tokenizer.convert_tokens_to_ids(\"공정변수\")\n",
        "print(\"Token ID for '공정변수':\", token_id)\n",
        "\n",
        "# 직접 인코딩과 디코딩을 통한 검증\n",
        "encoded_text = tokenizer.encode(\"공정변수\", add_special_tokens=False)\n",
        "decoded_text = tokenizer.decode(encoded_text)\n",
        "print(\"Encoded and Decoded Text:\", decoded_text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Token ID for '공정변수': 31021\nEncoded and Decoded Text: 공정변수\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715175503784
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_str = ' [CLS] 공정변수를 진공성형의 사출성형해석에 요인배치로써 공급부에 중요한 역할을 제공한다. [SEP]'\n",
        "print('테스트 문장: ',test_str)\n",
        "\n",
        "encoded_str = tokenizer.encode(test_str,add_special_tokens=False)\n",
        "print('문장 인코딩: ',encoded_str)\n",
        "\n",
        "decoded_str = tokenizer.decode(encoded_str)\n",
        "print('문장 디코딩: ',decoded_str)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "테스트 문장:   [CLS] 공정변수를 진공성형의 사출성형해석에 요인배치로써 공급부에 중요한 역할을 제공한다. [SEP]\n문장 인코딩:  [2, 34904, 31027, 33480, 30994, 2255, 31029, 17238, 14639, 11144, 15328, 10302, 17572, 13248, 8008, 17, 3]\n문장 디코딩:  [CLS] 공정변수를 진공 성형의 사출성형해석 에 요인 배치로써 공급부에 중요한 역할을 제공한다. [SEP]\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715175558144
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/trained_tokenizer/0508test_bertwordpiece/\")\n",
        "def chunk_text(text, chunk_size=5100):\n",
        "    token_ids = tokenizer.encode(text, add_special_tokens=False)  # 특수 토큰을 제외하고 인코딩\n",
        "    return [token_ids[i:i + chunk_size] for i in range(0, len(token_ids), chunk_size)]\n",
        "\n",
        "# 예시 텍스트\n",
        "text = \"공정변수를 진공성형의 사출성형해석에 요인배치로써 공급부에 중요한 역할을 제공한다.\"\n",
        "\n",
        "# 텍스트를 청크로 나누기\n",
        "chunks = chunk_text(text)\n",
        "\n",
        "# 각 청크를 별도로 처리\n",
        "for chunk in chunks:\n",
        "    inputs = tokenizer.decode(chunk, skip_special_tokens=True)  # 토큰 ID를 다시 텍스트로 디코드\n",
        "    print(inputs)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "사출성형해석 에 중요한 역할을 제공한다.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715143978330
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "text = '  공정변수를 진공성형의 사출성형해석에 요인배치로써 공급부에 중요한 역할을 제공한다. '\n",
        "tokenizer =BertTokenizerFast.from_pretrained(\"beomi/KcBERT-v2023\",do_lower_case=False)\n",
        "# 텍스트 토큰화\n",
        "tokenized_output = tokenizer.encode(text, add_special_tokens=False)\n",
        "print(tokenized_output)\n",
        "print(\"tokenizer len:\",len(tokenizer))\n",
        "# 토큰화 결과 출력\n",
        "for output in tokenized_output:\n",
        "    decoded_output = tokenizer.decode(output)\n",
        "    print(\"Decoded Text:\", decoded_output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \nThe class this function is called from is 'BertTokenizerFast'.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[225, 1856, 1221, 3132, 581, 621, 20893, 342, 364, 924, 20893, 322, 10240, 1271, 13342, 11746, 1486, 4736, 11378, 4289, 13756, 7260, 733, 18, 225]\ntokenizer len: 50265\nDecoded Text:  \nDecoded Text:  공정\nDecoded Text: 변\nDecoded Text: 수를\nDecoded Text:  진\nDecoded Text: 공\nDecoded Text: 성형\nDecoded Text: 의\nDecoded Text:  사\nDecoded Text: 출\nDecoded Text: 성형\nDecoded Text: 해\nDecoded Text: 석에\nDecoded Text:  요\nDecoded Text: 인배\nDecoded Text: 치로\nDecoded Text: 써\nDecoded Text:  공급\nDecoded Text: 부에\nDecoded Text:  중요한\nDecoded Text:  역할을\nDecoded Text:  제공\nDecoded Text: 한다\nDecoded Text: .\nDecoded Text:  \n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717049671425
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "llm-rag-embeddings",
      "language": "python",
      "display_name": "genai"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "llm-rag-embeddings"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}